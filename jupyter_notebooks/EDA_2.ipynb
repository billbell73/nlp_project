{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "2596"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('jobs_linkedin_html.pickle', 'rb') as handle:\n",
    "    jobs = pickle.load(handle)\n",
    "\n",
    "len(jobs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "break_counts = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "for key, value in jobs.items():\n",
    "    description = (value['description'])\n",
    "    break_counts.append(description.count('<br/>'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "2596"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(break_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([320., 279., 267., 291., 247., 324., 180., 143.,  96., 116.,  70.,\n         64.,  32.,  42.,  32.,  22.,  15.,  30.,   3.,   1.,   3.,   1.,\n          3.,   8.,   3.,   0.,   1.,   1.,   0.,   2.]),\n array([  0. ,   4.4,   8.8,  13.2,  17.6,  22. ,  26.4,  30.8,  35.2,\n         39.6,  44. ,  48.4,  52.8,  57.2,  61.6,  66. ,  70.4,  74.8,\n         79.2,  83.6,  88. ,  92.4,  96.8, 101.2, 105.6, 110. , 114.4,\n        118.8, 123.2, 127.6, 132. ]),\n <BarContainer object of 30 artists>)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQeUlEQVR4nO3dX4xc5X3G8e8TQ8nfKlAW5NhWTSO3DUSNqVYuLVVFQ1ociGJyQWXURJaK5FwQlVSRWpNcJLmwRNX8aS9KKidQrJZCrYQUi6RpXDdVFKmFLJQSjHFxgwsbXLxJmoa0EonJrxdzaCb2/pn17OzOvnw/0mrOeeecmWetnWeP3z1zJlWFJKktL1vpAJKkpWe5S1KDLHdJapDlLkkNstwlqUFnrXQAgPPPP782bty40jEkaVV58MEHv1lVE7PdNxblvnHjRqamplY6hiStKkn+Y677nJaRpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGjcU7VNWzcdfnBtru2C3XjDiJpNXOI3dJalATR+4e8UrSj/PIXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGrRguSd5eZIHkvxrkkNJPtyNn5fkQJInuttz+/a5OcnRJEeSXDXKb0CSdLpBjtyfB95cVW8CNgNbk1wG7AIOVtUm4GC3TpKLge3AJcBW4NYka0aQXZI0hwXLvXq+162e3X0VsA3Y243vBa7tlrcBd1fV81X1JHAU2LKUoSVJ8xtozj3JmiQPAyeAA1V1P3BhVR0H6G4v6DZfBzzdt/t0N3bqY+5MMpVkamZmZohvQZJ0qoHKvapeqKrNwHpgS5I3zrN5ZnuIWR5zT1VNVtXkxMTEQGElSYNZ1NkyVfUd4B/pzaU/m2QtQHd7ottsGtjQt9t64Jlhg0qSBjfI2TITSV7bLb8CeAvwOLAf2NFttgO4t1veD2xPck6Si4BNwANLnFuSNI9BPqxjLbC3O+PlZcC+qrovyT8B+5LcADwFXAdQVYeS7AMeA04CN1bVC6OJL0mazYLlXlWPAJfOMv4t4Mo59tkN7B46nSTpjDTxMXsrxY/3kzSuvPyAJDXIcpekBlnuktQgy12SGmS5S1KDLHdJatBL6lRIT12U9FLhkbskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ16SZ3nPqhBz4eXpHHlkbskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ1asNyTbEjypSSHkxxKclM3/qEk30jycPd1dd8+Nyc5muRIkqtG+Q1Ikk43yJuYTgLvq6qHkrwGeDDJge6+j1fVR/o3TnIxsB24BHgd8PdJfraqXljK4JKkuS145F5Vx6vqoW75OeAwsG6eXbYBd1fV81X1JHAU2LIUYSVJg1nUnHuSjcClwP3d0HuSPJLk9iTndmPrgKf7dptmll8GSXYmmUoyNTMzs/jkkqQ5DVzuSV4NfAZ4b1V9F/gE8HpgM3Ac+OiLm86ye502ULWnqiaranJiYmKxuSVJ8xjowmFJzqZX7HdW1T0AVfVs3/2fBO7rVqeBDX27rweeWZK0q5QXIpO03AY5WybAbcDhqvpY3/javs3eATzaLe8Htic5J8lFwCbggaWLLElayCBH7pcD7wK+luThbuz9wPVJNtObcjkGvBugqg4l2Qc8Ru9Mmxs9U0aSlteC5V5VX2H2efTPz7PPbmD3ELkkSUPwHaqS1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNWjBck+yIcmXkhxOcijJTd34eUkOJHmiuz23b5+bkxxNciTJVaP8BiRJpxvkyP0k8L6qegNwGXBjkouBXcDBqtoEHOzW6e7bDlwCbAVuTbJmFOElSbNbsNyr6nhVPdQtPwccBtYB24C93WZ7gWu75W3A3VX1fFU9CRwFtixxbknSPBY1555kI3ApcD9wYVUdh94vAOCCbrN1wNN9u013Y6c+1s4kU0mmZmZmziC6JGkuA5d7klcDnwHeW1XfnW/TWcbqtIGqPVU1WVWTExMTg8aQJA1goHJPcja9Yr+zqu7php9Nsra7fy1wohufBjb07b4eeGZp4kqSBjHI2TIBbgMOV9XH+u7aD+zolncA9/aNb09yTpKLgE3AA0sXWZK0kLMG2OZy4F3A15I83I29H7gF2JfkBuAp4DqAqjqUZB/wGL0zbW6sqheWOrgkaW4LlntVfYXZ59EBrpxjn93A7iFySZKG4DtUJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lq0CBvYtKY2bjrcwNve+yWa0aYRNK48shdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBi1Y7kluT3IiyaN9Yx9K8o0kD3dfV/fdd3OSo0mOJLlqVMElSXMb5Mj9DmDrLOMfr6rN3dfnAZJcDGwHLun2uTXJmqUKK0kazILlXlVfBr494ONtA+6uquer6kngKLBliHySpDMwzJz7e5I80k3bnNuNrQOe7ttmuhs7TZKdSaaSTM3MzAwRQ5J0qjMt908Arwc2A8eBj3bjmWXbmu0BqmpPVU1W1eTExMQZxpAkzeaMyr2qnq2qF6rqh8An+dHUyzSwoW/T9cAzw0WUJC3WGZV7krV9q+8AXjyTZj+wPck5SS4CNgEPDBdRkrRYZy20QZK7gCuA85NMAx8Erkiymd6UyzHg3QBVdSjJPuAx4CRwY1W9MJLkGsjGXZ8baLtjt1wz4iSSltOC5V5V188yfNs82+8Gdg8TSpI0HN+hKkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lq0IIf1iH185OdpNXBI3dJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUoAXLPcntSU4kebRv7LwkB5I80d2e23ffzUmOJjmS5KpRBZckzW2QI/c7gK2njO0CDlbVJuBgt06Si4HtwCXdPrcmWbNkaSVJA1mw3Kvqy8C3TxneBuztlvcC1/aN311Vz1fVk8BRYMvSRJUkDepM59wvrKrjAN3tBd34OuDpvu2mu7HTJNmZZCrJ1MzMzBnGkCTNZqn/oJpZxmq2DatqT1VNVtXkxMTEEseQpJe2M722zLNJ1lbV8SRrgRPd+DSwoW+79cAzwwTU8hj0mjGSVoczPXLfD+zolncA9/aNb09yTpKLgE3AA8NFlCQt1oJH7knuAq4Azk8yDXwQuAXYl+QG4CngOoCqOpRkH/AYcBK4sapeGFF2SdIcFiz3qrp+jruunGP73cDuYUJJkobjO1QlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIadKYf1iHNa9AP/zh2yzUjTiK9NHnkLkkNstwlqUGWuyQ1yDl3rSjn5qXR8MhdkhpkuUtSgyx3SWqQ5S5JDbLcJalBQ50tk+QY8BzwAnCyqiaTnAf8NbAROAb8VlX913AxJUmLsRRH7r9eVZurarJb3wUcrKpNwMFuXZK0jEYxLbMN2Nst7wWuHcFzSJLmMWy5F/DFJA8m2dmNXVhVxwG62wtm2zHJziRTSaZmZmaGjCFJ6jfsO1Qvr6pnklwAHEjy+KA7VtUeYA/A5ORkDZlDktRnqCP3qnqmuz0BfBbYAjybZC1Ad3ti2JCSpMU543JP8qokr3lxGfhN4FFgP7Cj22wHcO+wISVJizPMtMyFwGeTvPg4f1VVX0jyVWBfkhuAp4Drho8pSVqMMy73qvo68KZZxr8FXDlMKOlMDXqVSfBKk2qb71CVpAZZ7pLUIMtdkhpkuUtSgyx3SWqQn6GqVWExZ8Es9WN6Vo1WI4/cJalBHrlLy8z/MWg5eOQuSQ2y3CWpQZa7JDXIcpekBvkHVWkB/gFUq5FH7pLUIMtdkhpkuUtSg5xzl5bIKC6RIJ0pj9wlqUGWuyQ1yHKXpAZZ7pLUIP+gKmnkfCPY8vPIXZIaNLJyT7I1yZEkR5PsGtXzSJJON5JpmSRrgD8FfgOYBr6aZH9VPTaK55NatNRTGYs5D38Uj7mUj+f0zcJGNee+BThaVV8HSHI3sA2w3KUltpKfLzvuRvF9LPUvvlH9ohpVua8Dnu5bnwZ+qX+DJDuBnd3q95IcGeL5zge+OcT+K8Xcy8vcy2tkufOHo3jU/zdv7qV+7iEf76fnumNU5Z5ZxurHVqr2AHuW5MmSqaqaXIrHWk7mXl7mXl7mXlmj+oPqNLChb3098MyInkuSdIpRlftXgU1JLkryE8B2YP+InkuSdIqRTMtU1ckk7wH+DlgD3F5Vh0bxXJ0lmd5ZAeZeXuZeXuZeQamqhbeSJK0qvkNVkhpkuUtSg1Z1ua+WSxwk2ZDkS0kOJzmU5KZu/LwkB5I80d2eu9JZZ5NkTZJ/SXJftz72uZO8Nsmnkzze/bv/8irJ/Xvdz8ijSe5K8vJxzZ3k9iQnkjzaNzZn1iQ3d6/VI0muWpnUc+b+o+5n5ZEkn03y2r77xiL3Yq3acu+7xMFbgYuB65NcvLKp5nQSeF9VvQG4DLixy7oLOFhVm4CD3fo4ugk43Le+GnL/CfCFqvp54E308o917iTrgN8FJqvqjfRORtjO+Oa+A9h6ytisWbuf9+3AJd0+t3av4ZVwB6fnPgC8sap+Afg34GYYu9yLsmrLnb5LHFTV94EXL3EwdqrqeFU91C0/R69o1tHLu7fbbC9w7YoEnEeS9cA1wKf6hsc6d5KfBH4NuA2gqr5fVd9hzHN3zgJekeQs4JX03h8ylrmr6svAt08ZnivrNuDuqnq+qp4EjtJ7DS+72XJX1Rer6mS3+s/03psDY5R7sVZzuc92iYN1K5RlYEk2ApcC9wMXVtVx6P0CAC5YwWhz+WPg94Ef9o2Ne+6fAWaAP++mkz6V5FWMee6q+gbwEeAp4Djw31X1RcY89ynmyrqaXq+/A/xtt7yacv+Y1VzuC17iYNwkeTXwGeC9VfXdlc6zkCRvA05U1YMrnWWRzgJ+EfhEVV0K/A/jM5Uxp25+ehtwEfA64FVJ3rmyqZbMqni9JvkAvWnUO18cmmWzscs9m9Vc7qvqEgdJzqZX7HdW1T3d8LNJ1nb3rwVOrFS+OVwOvD3JMXrTXm9O8peMf+5pYLqq7u/WP02v7Mc991uAJ6tqpqp+ANwD/Arjn7vfXFnH/vWaZAfwNuC360dvABr73HNZzeW+ai5xkCT05n8PV9XH+u7aD+zolncA9y53tvlU1c1Vtb6qNtL79/2Hqnon45/7P4Gnk/xcN3QlvctNj3VuetMxlyV5ZfczcyW9v8+Me+5+c2XdD2xPck6Si4BNwAMrkG9WSbYCfwC8var+t++usc49r6patV/A1fT+sv3vwAdWOs88OX+V3n/lHgEe7r6uBn6K3hkFT3S356101nm+hyuA+7rlsc8NbAamun/zvwHOXSW5Pww8DjwK/AVwzrjmBu6i97eBH9A7wr1hvqzAB7rX6hHgrWOW+yi9ufUXX59/Nm65F/vl5QckqUGreVpGkjQHy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ16P8AzelOqTvBxA4AAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(break_counts, density=False, bins=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "line_counts = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "for key, value in jobs.items():\n",
    "    description = (value['description'])\n",
    "    soup = bs(description)\n",
    "    text = soup.get_text(\"|\", strip=True)\n",
    "    line_counts.append(text.count('|'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'The Real Estate Data Scientist will report to the Director of Real Estate Strategy. The Real Estate Data Scientist will be actively engaged in analytics on the individual store and market level to further help decide where to open successful Harbor Freight stores through time in the field and at corporate while assisting with the new store opening process. To be successful in this role, this individual will need a deep understanding of what makes a successful store, how to sustainably grow markets and new store growth strategy through data analysis supplemented with time visiting markets while performing additional project-based analyses and department level reporting as required to facilitate Harbor Freight’s growth. Based upon successful performance in this role, this position can be a stepping stone to either further roles in real estate strategy, or a number of other highly analytical roles within the organization such as Data Analytics, Corporate Strategy, Merchandising Finance to name a few.|Essential Duties And Responsibilities|Lead analytical support for various initiatives including, but not limited to:|Improve Harbor Freight’s existing site selection model by analyzing customer data and building a model that predicts sales per core customer, core customer and trade area drive time, with an intended accuracy of +/-15% for 80% of new store locations.|Understanding of Harbor Freight’s customer through statistical modeling on demographic, SKU level and financial data to develop a customer profile known as a “core customer”.|Manage monthly database mining to provide insight on customer behavior by region/market/SKU etc. for various departments.|Model demand potential for incremental stores as well as risk inherent in brand’s growth strategies for individual targets and at the market level.|Pro forma P & L and investment analysis for prospective sites.|Leverage time spent in the field to better understand risk around particular markets and refine the customer definition/model.|Various cross functional special projects and reporting requirements.|Leading pulse replies, quarterly post audits and other internal projects at the team level.|Lead the development and implementation of national demographic market planning and site evaluation systems and processes.|Manage the relationship and validate the output of third party software providers, demographic vendors, and other data providers to ensure the most accurate data is available to teams.|While this position will not have a supervisor relationship immediately with any junior analysts, we expect this position to share best in class knowledge, practices and tools to mentor.|Be a leader in the Real Estate Committee process for trade area and site information, whether it be preparing all material or presenting to the Real Estate Committee.|Drive consensus between Directors of Real Estate and Real Estate Strategy on which locations to prioritize for Harbor Freight Tools.|Lead cross functional adhoc projects ranging from understanding underperforming regions, to how changes in company strategy impact where we open stores to better educating business partners on the impact of opening stores to name a few.|Additional duties as assigned.|Requirements|Education and/or Experience:|A degree (Masters preferred) from a nationally recognized institution with outstanding academic credentials.|Direct experience in real estate strategy or 5+ year experience in consulting, investment banking, data analysis or financial analysis; with the majority of that experience in an analytical role.|Familiarity with retail and/or consumer products experience preferred.|Experience with R, SQL, Python, Alteryx preferred.|Considerable experience with Microsoft Office (advanced Excel and intermediate Access and PowerPoint skills) and other financial software / systems.|Superior analytical and quantitative skills, particularly in strategic business and financial analysis, driven by an intellectual curiosity to understand and explain relationships in data.|Strong ability to translate data from different sources and distill analyses into clear action plans.|Experience in CRM, Market Planning, Site Selection, and Market optimization preferred.|Experience with traveling for work on a frequent basis.|Experience and comfort working in a fast-paced business environment with ability to consistently meet tight deadlines.|Self-directed individual able to adapt quickly to changes in priorities and business conditions.|Team attitude and approach to work.|Physical Requirements|General office environment, ability to sit for long periods of time. Ability to move about an office.|Often travel may be required to see potential HFT locations and markets where existing stores are currently open.|Supervisory Responsibility|Staff supervision and development — no, mentorship/development yes|Decision making - see examples above|Travel – 20%|Location—Corporate Office Safety:|Must be able to perform this job safely in accordance with standard operating procedures and good manufacturing practices, without endangering the health or safety of self or others|Benefits Include|401K|Full Medical Package including, health and dental|Paid Time Off’|Competitive Salary|Casual Work Environment|Show more|Show less'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[17]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([ 35.,  51.,  40., 100., 174., 296., 271., 357., 309., 176., 215.,\n        118., 124.,  85.,  84.,  65.,  19.,  25.,  10.,   5.,  25.,   1.,\n          1.,   1.,   1.,   0.,   0.,   1.,   5.,   3.]),\n array([  2.        ,   5.56666667,   9.13333333,  12.7       ,\n         16.26666667,  19.83333333,  23.4       ,  26.96666667,\n         30.53333333,  34.1       ,  37.66666667,  41.23333333,\n         44.8       ,  48.36666667,  51.93333333,  55.5       ,\n         59.06666667,  62.63333333,  66.2       ,  69.76666667,\n         73.33333333,  76.9       ,  80.46666667,  84.03333333,\n         87.6       ,  91.16666667,  94.73333333,  98.3       ,\n        101.86666667, 105.43333333, 109.        ]),\n <BarContainer object of 30 artists>)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(line_counts, density=False, bins=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am looking for a self-motivated data scientist with machine learning experience. You will be working on a ground-breaking cloud R&D platform designed to integrate the volumes of scientific resources, helping to build a digital workplace with direct impact on human health, pharmaceutical research and Life Sciences companies. This opportunity requires a strong technical background in machine learning; utilizing methods for understanding large scale biological data.|Responsibilities:|•\tDesign and implement ML methods on proprietary and open-access datasets;|•\tUtilize large-scale datasets to generate statistically motivated research hypotheses;|•\tApply statistical methods to rigorously test and evaluate research hypotheses;|•\tDevelop and foster external collaborations;|•\tProvide expert technical guidance and support customers in the design and analysis of experiments;|•\tWork both independently and as part of a collaborative team to develop data analysis and machine learning solutions.|Requirements:|•\tPh.D. degree with 3+ years (or MS degree with 5+ years) of working experience in the industry in the field of systems biology, bioinformatics, computational biology, data science, ML, or equivalent;|•\tExtensive experience applying ML techniques to large scale genomics and/or high throughput biological data sets;|•\tStrong technical knowledge of molecular biology, genetics, and bioinformatics;|•\tProficient in either R or Python;|•\tExperience with ML frameworks such as Torch, PyTorch, TensorFlow, Scikit-learn, etc.;|•\tFamiliarity with Atlassian JIRA;|This is a fully remote position with a package of up to $200K plus benefits|Show more|Show less\n",
      "\n",
      "\n",
      "https://smu.taleo.net/careersection/ex/jobdetail.ftl?job=MEA00000091&tz=GMT-05%3A00&tzname=America%2FNew_York|The Data Scientist is responsible for managing and leveraging SMU DataArts’ databases and conducting analyses that support DataArts’ research agenda. DataArts’ data include objective financial and operating data for some 50,000 arts organizations, census data for businesses and households in all US census tracts, block groups and zip codes, and household-level arts patronage data for 30 million households. These data have been integrated into a spatial model of the arts and culture ecosystem.|The Data Scientist will analyze data holdings, develop schema in support of growth and extension, and design and configure Extract, Transform, and Load (ETL) processes such that the data fit into a unified data architectural model that meets business requirements. The ideal candidate will have a working knowledge of data architectures, database technologies (e.g., SQL), Cloud services (e.g., AWS), statistical computer languages (e.g., Python, R, SAS), and spatial statistics.|Essential Functions:|Data Wrangling: use Python to clean and integrate data from the Cultural Data Profile, the Internal Revenue Service, zip-code level business pattern data from the Census Bureau, census tract and block group level socioeconomic data from the Census Bureau, and household-level purchase data from TRG Arts and individual organizations.|Database Development: Work as the lead data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the engineering team to strategize and execute the development of a data warehouse.|Maintain and update the DataArts spatial model and online user tools such as the KIPI dashboard, the Arts Vibrancy Heat Map, and the Demand Prediction Tool.|Work with stakeholders throughout the organization to identify opportunities for leveraging data to drive solutions for clients as well as the company.|Qualifications|Education and Experience:|Master’s degree is required, preferably in data science, operations research, applied mathematics, statistics, economics, or physics. Ph.D is desirable.|A minimum of two years of work experience in data wrangling, database management, and the design, engineering, and implementation of end to end software solutions, from prototype through production pipeline is required.|Knowledge, Skills and Abilities:|Candidate must demonstrate strong verbal and interpersonal communication skills, as well as the ability to establish and maintain effective working relationships with a wide range of constituencies in a diverse community. Must also demonstrate the ability to communicate effectively in writing.|Candidate must have experience with multiple statistical languages (e.g., Python and R in Linux platforms) to query databases, manipulate data, and maintain large data sets. Strong relational database skills (e.g., MS SQL) and working knowledge of Cloud services (e.g., AWS) are also required.|Candidate must possess strong time management, organizational and planning skills. Must also possess strong project management skills.|Candidate must have a strong understanding of the data analysis process, including data exploration and ETL processes, automated processes for data quality assurance, problem specification, data modeling and evaluation.|Candidates must have demonstrated skills in: Python and R in Linux platforms, and managing relational databases such as MS SQL. Proficiency in using UNIX OS in high performance environment and data visualization experience are also desirable.|https://smu.taleo.net/careersection/ex/jobdetail.ftl?job=MEA00000091&tz=GMT-05%3A00&tzname=America%2FNew_York|Show more|Show less\n",
      "\n",
      "\n",
      "Role: Senior Analyst|Key Responsibilities:|• Provide consultative support as and when required and should be able|to handle complex|projects independently|• Perform exploratory data analysis, data deep dives and generate data|insights|• Substantial portion of work would require advanced Data Modelling and|Data Wrangling|• Responsible for implementing multiple model types/methodologies, will|design, test and|architect variety of models based on business requirements|• Build relationships with clients to better understand their business,|and to enable them to|better understand how to use analytics to drive their business|• Develop code, statistical models, dashboards and presentations as per|client requirements|• Present the results of the work to client stake holders and give|insights and|recommendations that have tangible business impacts|• Work with onsite and offshore team to structure solutions based on|analytics tools and|techniques|• Compliance of structured problem-solving approach and documentation of|the same|• Assist the team in process improvement / automation to increase|efficiency|• Build and maintain strong relationships with external and internal|stakeholders|Knowledge:|Qualification:|− BE / B. Tech/Master's in Computer science/Business Analytics/|Statistics|Experience:|− 3-5 years of relevant experience in analytics consulting and|professional services|− At least 1-3 years hands on experience in creating visualizations and|dashboards through insights|− Hands-on experience working with large, complex, and diverse|datasets|− Consultative approach and ability to apply first principles and|structured approaches to problem solving as opposed to relying|excessively on past domain expertise alone|− Ecommerce and Retail experience strongly preferred|Skills:|Technical/Domain:|− 1-3 years of experience working with Tableau and analysing large|datasets|− Strong SQL query skills and experience in BI Dashboards required|− Experience with Exploratory Data Analysis|− At least 1+ year of experience working with Python / R programming|Competencies:|Behavioural:|− Must have exceptional and effective communication,|organization, and time management skills|− Must be pro-active and determined (Initiates action, Analytical|and problem solver)|Show more|Show less\n",
      "\n",
      "\n",
      "The ideal candidate has proficiency with major data science tools and languages such as SQL, Python, R, AWS eco system, NiFi, and Git|4+ Years real world data science AI/ML model development and deployment experience|Retrieve, manipulate, relate and/or exploit multiple structured and unstructured datasets from various sources.|Initiate the efficient implementation of methods, tools, and algorithms, including preliminary data exploration, data preparation, data visualization, model calibration, and algorithm validation/verification using a comprehensive range of technologies (e.g., software packages, programming languages, computational environments).|Transform data into usable datasets through development of data structures, designing a data sampling strategy, designing the data preparation flow|Expertise deploying ML and AI algorithms for solving real world problems|Experience working in AWS environment|Strong expertise in Python|Good to Have: Experience with NoSQL databases, Kafka, NiFi|Must have experience with NLP and Voice transcription|Show more|Show less\n",
      "\n",
      "\n",
      "Job Description:|•\tExpertise in predictive modeling, machine learning, and statistics.|•\tSoftware development skills in one or more high level languages (Python/Java/R/Scala).|•\tExperience using one or more of the following common ML software packages: scikit-learn, TensorFlow, NumPy, pandas, jupyter.|•\tWell-versed in machine learning algorithms and their suitability for solving various problems: Regression, Bayesian, Support Vector Machines, Decision Trees, Random Forest, Clustering, Neural Networks.|•\tExperience in using SQL/No SQL databases is preferred|•\tExperience working in Linux is an advantage|•\tExperience with Big Data technologies is preferred (Hadoop, Hive, Spark, Cassandra).|•\tExperience with building and deploying data pipelines|•\tGood critical thinking, technical, data collection and user interviewing skills.|•\tAbility to work as a team member in a fast-paced environment.|•\tExperience with Agile software development processes is preferred.|•\tExperience with Cloud service offerings from AWS, Azure or GCP is a plus|Show more|Show less\n",
      "\n",
      "\n",
      "Experience level: Associate Experience required: 6 Years Education level: Bachelor’s degree Job function: Information Technology Industry: Financial Services Compensation:|Greencard holders preferred. Will consider other options for the right candidate|We are one of the world's most trusted financial data and research providers in the options markets. We are looking for a few good Software Engineers to join our group. If you are passionate, driven, and eager to learn new technologies...if you love spending weekends with friends and family instead of production support...and the idea of working alongside exceptionally bright and creative developers and quants excites you, we need to talk!|As a Software Engineer, you will have a variety of technologies to work with. Python, Java, C++, Go, JavaScript, we use them all! Our infrastructure is 100% cloud-based, which means you can finally say goodbye to soul-crushing technical debt and hello to cutting-edge tools and tech! You will develop applications accessing large financial data sets. You will be collaborating daily to brainstorm and implement our next generation of data and analytic information products.|Here we emphasize accountability over micromanagement. We invest in our talent with free learning resources like Udemy courses, O'Reilly subscriptions, even pay for conferences and certification exams! We're small, agile, casual (no suits – shoes optional), and passionate about our mission and the projects we create. As a development team member, you will have true ownership over your projects from beginning to end.|Our Technology Stack:|Languages: Java, Python, C++, JavaScript, Go|Databases: Postgres, MS SQL Server, RDS, Aurora|Frameworks: Spring Boot, Serverless, Vue|Data Analysis: AWS EMR, Spark, Athena|The Software Engineer Will:|For 2 positions:|Have 6+ years of experience with a mix of Java, Python, SQL, and cloud experience. Go, Vue, React, or JavaScript would be a plus.|Develop applications accessing large financial data sets|Assist with the troubleshooting of production support issues|Enjoy the challenge of researching data issues to maintain quality in our large data sets|Gain an understanding of the complex math associated with Options|What We Offer:|A collaborative environment where everyone's input makes a difference|Paid time off: Vacation, Personal, Sick days, and Holidays|401k plan with matching|Full medical and dental insurance coverage|Pre-tax commuter benefits|The usual snacks and drinks!|The company began over 20 years ago with the goal of becoming the world's most trusted provider of financial information and research derived from the option markets. Today, our data and analytics models are used by over 350 investment banks, hedge funds, asset managers, and academic institutions worldwide.|Show more|Show less\n",
      "\n",
      "\n",
      "Project Canary is a growth-stage, SaaS and certification company combatting climate-change from an incredible vantage point that can impact oil & gas, utilities, landfills, and ag. We are a Public Benefit Corp (B-Corp rating score 107) that helps monitor and mitigate emissions in the ESG landscape favored by communities and investors alike through independent data tied to carbon and environmental footprints. With flexible work environments in Denver,|Project Canary’s mission is to make net-zero a reality by quantifying climate change and putting actionable insights into the hands of the energy sector. Our diverse and inclusive team of operators, scientists, engineers, and sales leaders know how to network, hustle, and are change-makers by design. We ingest data from various sources, including our own proprietary environmental sensors/hardware, to calculate carbon emissions from different facilities in real-time displayed on a SaaS dashboard. The resulting independent, trusted data can inform the procurement of offsets in real-time using microtransactions, formulate a data-driven ESG strategy that investors now demand, improve operations by identifying problem areas in minutes, and bolster customer engagement through radical supply chain transparency.|Initially, we are focused on the energy industry. With thousands of energy assets analyzed and hundreds of environmental and air quality sensors currently deployed, Project Canary is positioned better than anyone to provide empirical ESG data—and we have the ARR and growing pains to prove it.|Project Canary’s success is attributed to the motivation, skill, and teamwork of everyone. The team understands the importance of maintaining a culture where relationships are valued, feedback is crucial, and trust in each other and our products/services is paramount. If you enjoy a growth-stage environment, mission-driven work, we want to hear from you.|As a scaling PBC, we have excellent healthcare, a people-first orientation, and a sustainability core.|The Data Scientist will be part of the Data and Analytics team responsible for research and development of advanced predictive modeling to diverse problems across the oil and gas, utilities, and waste management value chain.|You are a team player who has a significant academic and industrial experience applying first principle-based models such as CFD and reduced order models and state of the art machine learning (Regression, Classification, Decision Trees, Random Forests) and deep learning techniques (CNN, RNN, LSTM, GRU).|Job Responsibilities:|Support Data and Analytics team through development of plume dispersion modeling to resolve complex fluid problems in an open field|Execute the certification through the review of a company's documentation, personnel interviews, and evaluation of well pad design|Assist the development of white papers for quantification analysis as well as additional technical and professional writing|Engagement with various disciplines within the Project Canary team including science, software, and regulatory members|Develop and support scientific projects that enhance our understanding of methane emission patterns and opportunities for enhanced methane mitigation from production and distribution of oil and gas globally|Play a role in designing, planning and execution of PC expanding work on quantifying methane emissions using first principal engineering methods, mathematical models, and statistical analysis|Coordinate and ensure rigor of scientific initiatives collaboratively undertaken with a diverse group of stakeholders including industry, academics, multilateral organizations, and the public sector|Remain at the forefront of climate science, including staying up to date with scientific literature|Requirements|Education and experience:|3+ years' experience quantifying emissions data|Strong background in fluid flow, CFD, Data Analytics|Competent in programming languages such as Python, C#, and Matlab|At least a bachelor's degree in Mechanical Engineering or relevant engineering field|Advanced degree and/or professional certifications helpful|Experience in performing rigorous analysis with short deadlines in support of highly visible work|Demonstrated scientific expertise, including but not limited to a record of scholarly publications and/or involvement in scientific panels|Experience synthesizing, interpreting, and communicating scientific data in an advocacy setting and for non-scientific populations|Vaccination required|Benefits|Full coverage of health, dental, and vision insurance|401K company match|Student loan assistance|Salary range: $90,000- $120,000 annual base|Stock options|World recognized work culture - ranked top 5% of all B-Corps|Project Canary provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.|This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.|Show more|Show less\n",
      "\n",
      "\n",
      "Gauntlet’s mission is to drive adoption and understanding of the financial systems of the future. Gauntlet is the platform for off-chain intelligence that drives on-chain efficiency in Decentralized Finance (DeFi). We work with protocols to manage risk, improve capital efficiency, and manage incentive spend. We also publish cutting-edge research and aim to take a leading role in defining market risk standards across the industry.|Gauntlet is building infrastructure that allows us to simulate and stress-test blockchain protocols, contracts, and network interactions at scale over a wide range of market conditions. Our models ingest a wide range of on-chain and off-chain data, and are continuously calibrated to the current crypto market structure so that our recommendations are always up-to-date. These models and infrastructure power our platform that currently manages risk and optimizes incentives for over $40B in assets.|You will be working as part of an experienced team to develop industry-leading products and infrastructure that will enable DeFi to achieve greater efficiency and impact.|Responsibilities|Build agent-based simulations of smart contracts and blockchain networks using our Python SDK|Design and optimize incentive models for blockchain protocols and help discover potential attack vectors|Contribute to making our simulation model and platform world-class|Build data models and visualizations of public blockchain data and simulation results that provide intuitive analytics to customers|Qualifications|Proficient at writing code in Python or similar languages|Experience with scientific computing packages such as Numpy/Scipy, Pandas, etc..|Experience with distributed computation frameworks such as Spark, Flink, TensorFlow|Bonus Points|Smart contract development experience (e.g. Solidity)|Experience with building machine learning models at scale|Benefits and Perks|Remote first - work from anywhere!|Regular in-person company retreats and cross-country \"office visit\" perk|100% paid medical, dental and vision premiums for employees|Laptop, monitor, keyboard and mouse setup provided|$1,000 WFH stipend upon joining|$100 per month reimbursement for fitness-related expenses|Monthly reimbursement for home internet, phone, and cellular data|Unlimited vacation|100% paid parental leave of 12 weeks|Fertility benefits|Opportunity for incentive compensation|Show more|Show less\n",
      "\n",
      "\n",
      "Miles is a universal rewards app empowering anyone to earn miles automatically for all forms of travel and commute. You can then redeem your miles from amazing brands such as HP, Garmin, Pandora, Chewy, Home Chef, Buffalo Wild Wings, Wayfair, Sam’s Club and many more.|Similar to a frequent flyer program, but for all forms of transportation, Miles delivers value for every mile traveled, across every mode of travel, anywhere in the world. Whether by car (as a driver, passenger, or rideshare), plane, train, subway, bus, boat, bicycle, or on foot, the Miles app effortlessly awards users’ travel - regardless of where their journey takes them. Miles can be saved or redeemed at any time - with the value increasing every month as more merchants accept them as a form of payment.|Miles is a Silicon Valley-based startup with backing from prominent VCs (Porsche, Scrum, Panasonic, and Urban.us). Join the Miles family and be part of this revolutionary program!|Miles Engineering|You will be working with a great team from diverse backgrounds in a collaborative and supportive environment. We solve a wide variety of interesting technical challenges, and continually build up our platform to power the next generation of scale and features. We partner closely with Product, Design, and UX teams to build and ship the most impactful|You want to join an early startup on a fast growth trajectory. You are self motivated, take end to end ownership, communicate effectively, and are a fast learner.|Responsibilities|Productionize, launch, and monitor predictive models with high-dimensional, fast-moving real-time datasets.|Design, analyze, and manage both simulated and live experiments (A/B and multivariate tests) to drive KPI improvements.|Lead end-to-end cross functional analytics projects: scope requirements with stakeholders, collect and analyze data, as well as summarize and present key insights in support of critical decision making.|Analysis of large amounts of data to gather insights, identify trends, detect anomalies, develop key KPIs, and feed powerful dashboards and visualizations.|Build new and improve existing ML models by incorporating new sources, developing and testing model improvements, running experiments, and fine tuning parameters.|Requirements|Master’s or PhD degree in a quantitative field such as Machine Learning, Data Science, Statistics, Applied Mathematics, or Physics. Experience with data analysis and statistical modeling using Python packages such as pandas, scipy, statsmodels, scikit-learn, etc.|Communicate key data insights & recommendations to technical & non-technical stakeholders using visualizations (Tableau, Databox etc)|Familiarity with statistical and machine learning techniques to solve practical business problems.|Expertise with querying data (SQL, Redshift, Spark) and analyzing millions to billions of rows of data points.|Experience building machine learning, statistical, and analytical models, and tuning parameters.|Experience designing experiments, extracting insights, and writing testable code.|Bonus points|You have worked extensively with geospatial data at scale.|Prior experience in handling large datasets (billion+)|Specialization in spatio temporal clustering in the presence of noise.|Prior startup experience.|Benefits|Competitive salary based on experience|Opportunity to create impact in a high growth startup environment|401K program with company matching to help you invest in your future|Employee healthcare benefits include medical, dental, vision insurance|Paid time off + sick days|Work-from-home Fridays|Wellness Day - One additional holiday each month for employee wellness|Employee Referral bonus|Daily office meals and fully stocked kitchen|Monthly team-building activities and happy hours|Monthly gift cards|Stock in an early-stage fast-growing startup company|Our Commitment to Inclusivity and Diversity|Miles is committed to creating an inclusive and diverse environment where people of every background can thrive and feel welcome. We consider applicants without regard to race, color, creed, religion, national origin, genetic information, gender identity or expression, sexual orientation, pregnancy, age, marital, veteran, or physical or mental disability status.|Show more|Show less\n",
      "\n",
      "\n",
      "Role: Data Scientist|Remote|Duration: 4 Months Contract and Extending to a Year (W2)|USC or GC only|Tech Skills – SQL, Python and system automation|Soft skills – Work cross functionally, establish vision, build alignment on approach, incorporate feedback|Nice to Have:|Tech Skills – Tableau, Excel and Web reporting|Soft skills – Qualifications:|Data Analytics as part of a small team (not individual contributor)|Worked in an Agile Team (stand-ups, retros, demos)|Strong Communication skills (concise, clear, assertive)|Presentation Skills (client presentations, drawing conclusions)|Show more|Show less\n",
      "\n",
      "\n",
      "This is a contract position for 6 months to start|Hybrid role. Will be onsite 2-3 days per week|Will be running data science and analyses on clinical contracts looking for trends and anomalies|Programming skill such as python, R, SQL nice to have|Data visualization experience is nice to have|Data mining/modeling (e.g. statistical models) and enhancing data collection procedures to identify patterns and extract knowledge from large data sets|Processing, cleansing, and verifying the integrity of data used for analysis|Maintain thorough and current knowledge and understanding of GCP, ICH and GLP regulations associated with the maintenance and retention of clinical agreements|Collaborate with Development Business Operations leadership, Development Business Operations functional groups, clinical operations teams, and functional areas outside of Development Business Operations to ensure compliance with policies, procedures, and the practices of company records management/TMF archival initiative|Work with management and DMT personnel in the development, implementation and maintenance of classification and filing systems to meet administrative, research, regulatory, legal, and financial requirements (e.g. filing of agreements in legal archive, Apttus, and eTMF GDAR system)|Show more|Show less\n",
      "\n",
      "\n",
      "** Please note we are seeking candidates who have recently graduated with a bachelor's or master's degree and who have limited professional experience.**|Data Scientist - Digital Manufacturing|Location:                                                              Pflugerville, TX|Responsible Manager:|Sr. Manager Metals Technology|HERE’S WHAT YOU’LL BE DOING:|Analyze sensor data from EOS machines to identify root causes of build crashes, build prescriptive analytics and optimize additive manufacturing processes|Create and deploy analytics as products in revenue generating platforms and service|Close cooperation with the digital services group to market and sell analytics|Perform statistical analyses on part quality data and machine maintenance data to identify deficiencies in the manufacturing process|Analyze and consult on customer data projects with a focus on resolving pain points, generating analytics use cases and improving customer productivity|Act as a data analysis expert for internal development projects|Consult and work on projects with ITAR restrictions|Consult with customers on image analysis projects|Create framework for material database solutions|HERE’S WHAT WE ARE LOOKING FOR:|You are a careful and efficient problem solver with a passion for taking deep dives into complex data sets. You are comfortable analyzing data by writing scripts in Python or R, and you can communicate your findings with appropriately formatted charts and graphs. In addition to some practical experience working with additive manufacturing technology, you are interested in digital manufacturing, industry 4.0, smart factories and other cutting edge manufacturing technologies.|You also bring the following:|Successfully completed bachelor’s or master’s degree in engineering, physics, chemistry, biochemistry or computer science with a strong focus on data analysis.|Practical experience using data to solve problems.|Experience with additive manufacturing, either in an academic or professional environment|Practical knowledge and programming experience with Python or R|Basic understanding of statistical analysis, including descriptive statistics, design of experiments and Bayesian inference|Knowledge of machine learning, deep learning or multivariate statistics is a plus|US person status (Green card or US Citizen)|Native fluency in English required, proficiency in other languages, especially German, is a plus.|HERE’S WHAT WE ARE OFFER YOU AT EOS:|PURPOSE – We develop products with optimized energy consumption and recyclable components, we drive innovations which are socially relevant – so that our actions have a meaning.|DIVERSITY – No matter where you come from or what makes you tick; we want to engage new perspectives. We believe this diversity of thought will drive EOS’s future success – because together we simply achieve more.|EXCELLENCE – We develop individual learning journeys and offer different education opportunities at our EOS Academy – so you can grow and exhibit your best self.|SECURITY – We’re a successful family business and our technology is future-oriented – so you can plan your life.|FLEXIBILITY – We juggle working time models, home office, and new work concepts, offer benefits for public transport, bike leasing, and charging stations for electric cars – so you can live your lifestyle.|HEALTH – We offer health care course, ergonomics coaching, support joint sports activities, and online offers for relaxation – so you can feel good and stay healthy.|INTERESTED? SEND YOUR RESUME TO: careers@eos-na.com|Show more|Show less\n",
      "\n",
      "\n",
      "Company Description|Baanyan Software Services is a premier technology staffing and placement form serving clients since 2009. We are dedicated towards fulfilling it needs of our clients. We provide a broad range of employment services and the best practices approach. From last-minute feelings to long-term strategic staffing plans; from a single high-level executive placement to a project team of specialists; we have developed effective strategies for finding and screening the most qualified staff based on our clients' needs.|Job Overview|At Baanyan, you can participate in our practical training courses and mock interview sessions without paying any fee. You will be working in a project-based environment, which provides you the opportunity to work with multiple international cooperation and diverse teams. If you are looking for challenging work and opportunities for professional growth, don't hesitate to send us your application.|Qualification|Technical background required. (Java, SQL, C++, HTML, Tableau, Python etc.)|Preferred Qualification|Master's degree|Visa status - H4EAD/ L2EA/ OPT/ F1 EAD/ CPT (with 1 yr work experience) / Citizens|Benefits|Free training and placement|Full-time position with professional growth opportunities|Twice a month on-time Payrolls|H1B/ GC sponsorship|Medical insurance (health, eye, and dental)|401k|Guesthouse facilities|Relocation benefits|Contact|Campus Recruiter|Jean Chen|For further discussion, please message through LinkedIn or email jchen@baanyan.com|(732)595-9006 #113|Show more|Show less\n",
      "\n",
      "\n",
      "About Endgame 🌎|Endgame is building software for product-led sales. We make it easy to observe what’s happening in your trial or free motion, prioritize sales-ready accounts and users based on behavioral signals, and act on them to drive more revenue faster.|As a tight-knit team of developers and designers working across the continental US, we love tackling annoying problems and building elegant solutions for them. We believe that the way traditional businesses sell software is fundamentally broken. In the past, software was sold top-down to executives by expensive sales reps. Today's customers buy software by starting with a free trial, seeing value, then doubling down on the products they like. This is the future.|We have raised $47.5M and are backed by Menlo Ventures, Upfront, Unusual Ventures, and EQT Ventures.|Your mission 🚀|We're looking for a Data Scientist to join our team and help us build the world's best observability platform for sales.|You would be part of the Endgame's founding team, reporting directly to the Head of Engineering. You'll be working closely with the founders and the engineering team to create and scale a data platform to millions of observations. If you are looking for a role where you can influence both the company culture and product experience, read on.|Your responsibilities 🗓|You will lead the ideation, prototyping, and production of Endgame's data science features|You will work cross-functionally to understand our ideal customer profile and help come up with innovative data science solutions to solve their pain points|You will analyze large and novel datasets to extract actionable insights to inform business decisions and understand customer behavior|Using data analysis and research, you will work to uncover where opportunities for Endgame sit within the data|You will be building intelligence capabilities for product-led growth|Our ideal candidate 🏅|You have 5+ years of industry experience as a data scientist in high-growth environments|You have previous experience with correlation vs causation analysis.|You have the ability to extract complex analytical solutions in actionable understanding along with strong written and verbal skills|You are guided by curiosity and the commitment to continually ask questions of our data and business|You have expert level skills in Python data science toolkit (pandas, numpy, etc.) as well as SQL|Our benefits 🏆|Work remotely, no commuting to the office|Competitive salary and equity|401k, Health, dental, and vision insurance (US)|Macbook Pro, monitor, and accessories|Latest productivity software like Notion|Flexible time off (at least 20 days/year recommended)|Parental leave|Family friendly culture|Show more|Show less\n",
      "\n",
      "\n",
      "Senior Data Scientist|Join Us|HealthCare.com is looking to grow our elite Data Science team. As a Senior Data Scientist you will be part of the design, development, and deployment of Healthcare Inc.’s machine learning platform including: feature vector generation, experiment design, model generation, model evaluation. You will collaborate with both data engineers, clinical, and product towards building the models and rule generation that will drive Healthcare’s guidance platform to insure, ensure, and assure.|As a Senior Data Scientist you will answer core business questions like what products work for whom, what target audiences to engage, what solutions to implement at each stage of the customer journey, solutions for improving engagement and conversion rates, and identify marketplace dynamics. This opportunity is great for professionals with a shared vision of building an extraordinary platform and serve healthcare consumers through the power of data science!|About the Company|Founded in 2014, HealthCare.com is a privately-owned company whose mission is to help consumers make better healthcare decisions. We’re focused on improving how people shop for and enroll in health insurance coverage through data, content, and superior customer service. Our mission is to empower individuals, families, and small businesses by providing information and recommendations. We have an elite team of over 170 teammates in Miami, Indianapolis, New York City, Guatemala City, and distributed around the globe.|What You’ll Do:|Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.|Work with large, complex data sets|Build and develop all necessary data pipelines|Develop and deploy streaming microservices that enrich the raw data with knowledge and models Develop and deploy standard evaluation frameworks|Develop and deploy per member optimization simulations across financial, clinical and experience outcome variables|Contribute to the success of the team with specific experiment and research directions that can take our guidance platform to the next level|Develop predictive and prescriptive models|Who You Are:|You have an entrepreneurial spirit|You’re able to inspire through your work and motivate others|You have the ability to be both strategic and tactical|What You Have:|M.S. or Ph.D. degree in Computer Science, Mathematics, Statistics, Physics or related quantitative fieldsExperience in high concurrency distributed platforms and applied mathematics|Work experience with distributing Computing: Scala, Spark, Hadoop, Hive, HDFS, Cassandra, ElasticSearch Building and developing data pipelines|Experience leveraging public data sources to enhance machine learning|Strong programming experience in Python and/or R: including pandas, numpy, scipy, sklearn, seaborn, plotly|Machine learning experience: DeepLearning, Random Forests, gradient boosting, logistic regression, time-series, k-mean, built Lasso regression, vector embeddings, and more|Experience with ML Platforms like: SageMaker, Tensorflow, Matlab, and others|Understanding of metrics like precision/recall curves, ROC and more|Ability to handle large volumes of heterogeneous medical data|Experience building and designing feature vectors, application of multiple machine learning architectures such as deep learning (MPL, RSTM, etc), Random Forest, Bayesian, Regression, model validation ROC and Precision/Recall, Ensemble models, multi-Ranking, Embeddings, and others|Advanced experience prototyping predictive models on various tasks, and having finished with initial tests, confirmed by domain experts|The Perks|Medical, dental, and vision with 100% company paid premiums for the employee|Up to 15 days of paid time off|10 company observed holidays with an additional 3 floating holidays|Annual learning and development stipend|8 weeks of paid parental leave|EAP services|401k plan with company match|Most importantly, an inclusive company culture established by an incredible team!|Get to Know Us!|https://www.healthcare.com/|linkedin.com/company/healthcare-com|Show more|Show less\n",
      "\n",
      "\n",
      "Data Analytics Consultant|Full time opportunity|Work location: Livonia, MI|Need 2 resources|OPT with genuine experience will be considered..|Must have: R, Shiny, SQL, ETL|Education & experience:|Master’s degree in Data Analytics, Data mining, Statistics, Business Analytics, Actuarial Science or related field of study.|Minimum 3 years’ experience working as Data Analytics Consultant.|Job duties/ Responsibilities:|Strong expertise in data analysis, extraction, visualization|Expert level experience in R, SQL, Shiny|Experience in python, Tableau is highly preferred|Demonstrate the ability in Data cleansing, manipulation is required|Knowledge in ETL/ EDW is required|Good to have experience with Hadoop and Apache Spark|Healthcare experience is highly preferred.|Show more|Show less\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for key, value in jobs.items():\n",
    "    description = (value['description'])\n",
    "    soup = bs(description)\n",
    "    text = soup.get_text(\"|\", strip=True)\n",
    "\n",
    "    print(text)\n",
    "    print('\\n')\n",
    "    counter += 1\n",
    "    if (counter > 15):\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "[':|•\\tDesign and implement ML methods on proprietary and open-access datasets;|•\\tUtilize large-scale datasets to generate statistically motivated research hypotheses;|•\\tApply statistical methods to rigorously test and evaluate research hypotheses;|•\\tDevelop and foster external collaborations;|•\\tProvide expert technical guidance and support customers in the design and analysis of experiments;|•\\tependently and as part of a collaborative team to develop data analysis and machine learning solutions.']"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = \".|Responsibilities:|•\tDesign and implement ML methods on proprietary and open-access datasets;|•\tUtilize large-scale datasets to generate statistically motivated research hypotheses;|•\tApply statistical methods to rigorously test and evaluate research hypotheses;|•\tDevelop and foster external collaborations;|•\tProvide expert technical guidance and support customers in the design and analysis of experiments;|•\tependently and as part of a collaborative team to develop data analysis and machine learning solutions.|Requirements:|•\tWork both independently and as part of a collaborative team to develop data analysis and machine learning solutions.|Requirements:|•\tP\"\n",
    "\n",
    "\n",
    "# pattern = \"(?<=Responsibilities).*?(||)\"\n",
    "pattern = \"Responsibilities(.*?)\\|.{0,20}\\|\"\n",
    "\n",
    "match = re.findall(pattern, example_text)\n",
    "match"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# pattern = \"Responsibilities(.*?)\\|.{0,16}\\|\"\n",
    "pattern_start = \"[Rr]esponsibilities|[Ww]hat [Yy]ou['’]ll|[Ww]hat [Yy]ou [Ww]ill|[Dd]uties|[Tt]he [Rr]ole.{0,10}\\||[Oo]verview|[Ww]ork.{0,10}\\|\"\n",
    "# pattern_end = \"\\|.{0,16}\\||requirements|qualifications|skills.{0,10}\\||looking for|you have\"\n",
    "pattern_end = \"Requirements|[Qq]ualifications|Skills.{0,10}\\||[Ll]ooking [Ff]or.{0,5}\\||[Yy]ou [Hh]ave:\"\n",
    "\n",
    "pattern = f\"(?:{pattern_start})(.*?)(?:{pattern_end})\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "job_responsibilities = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "2596"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "# pattern = \"Responsibilities(.*?)\\|.{0,16}\\|\"\n",
    "# pattern = \"(?:responsibilities|what you['’]ll)(.*?)(?:\\|.{0,16}\\||requirements|qualifications|skills|looking for|you have)\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for key, value in jobs.items():\n",
    "    description = (value['description'])\n",
    "    soup = bs(description)\n",
    "    text = soup.get_text(\"|\", strip=True)\n",
    "\n",
    "    match = re.findall(pattern, text)\n",
    "\n",
    "    if match and len(match[0]) > 75:\n",
    "        job_responsibilities[key] = match[0]\n",
    "\n",
    "    counter += 1\n",
    "#     if (counter > 30):\n",
    "#         break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2908496770\n",
      "\n",
      ":|•\tDesign and implement ML methods on proprietary and open-access datasets;|•\tUtilize large-scale datasets to generate statistically motivated research hypotheses;|•\tApply statistical methods to rigorously test and evaluate research hypotheses;|•\tDevelop and foster external collaborations;|•\tProvide expert technical guidance and support customers in the design and analysis of experiments;|•\tWork both independently and as part of a collaborative team to develop data analysis and machine learning solutions.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2911267267\n",
      "\n",
      ":|• Provide consultative support as and when required and should be able|to handle complex|projects independently|• Perform exploratory data analysis, data deep dives and generate data|insights|• Substantial portion of work would require advanced Data Modelling and|Data Wrangling|• Responsible for implementing multiple model types/methodologies, will|design, test and|architect variety of models based on business requirements|• Build relationships with clients to better understand their business,|and to enable them to|better understand how to use analytics to drive their business|• Develop code, statistical models, dashboards and presentations as per|client requirements|• Present the results of the work to client stake holders and give|insights and|recommendations that have tangible business impacts|• Work with onsite and offshore team to structure solutions based on|analytics tools and|techniques|• Compliance of structured problem-solving approach and documentation of|the same|• Assist the team in process improvement / automation to increase|efficiency|• Build and maintain strong relationships with external and internal|stakeholders|Knowledge:|Qualification:|− BE / B. Tech/Master's in Computer science/Business Analytics/|Statistics|Experience:|− 3-5 years of relevant experience in analytics consulting and|professional services|− At least 1-3 years hands on experience in creating visualizations and|dashboards through insights|− Hands-on experience working with large, complex, and diverse|datasets|− Consultative approach and ability to apply first principles and|structured approaches to problem solving as opposed to relying|excessively on past domain expertise alone|− Ecommerce and Retail experience strongly preferred|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912844894\n",
      "\n",
      ":|Support Data and Analytics team through development of plume dispersion modeling to resolve complex fluid problems in an open field|Execute the certification through the review of a company's documentation, personnel interviews, and evaluation of well pad design|Assist the development of white papers for quantification analysis as well as additional technical and professional writing|Engagement with various disciplines within the Project Canary team including science, software, and regulatory members|Develop and support scientific projects that enhance our understanding of methane emission patterns and opportunities for enhanced methane mitigation from production and distribution of oil and gas globally|Play a role in designing, planning and execution of PC expanding work on quantifying methane emissions using first principal engineering methods, mathematical models, and statistical analysis|Coordinate and ensure rigor of scientific initiatives collaboratively undertaken with a diverse group of stakeholders including industry, academics, multilateral organizations, and the public sector|Remain at the forefront of climate science, including staying up to date with scientific literature|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2911205495\n",
      "\n",
      "|Build agent-based simulations of smart contracts and blockchain networks using our Python SDK|Design and optimize incentive models for blockchain protocols and help discover potential attack vectors|Contribute to making our simulation model and platform world-class|Build data models and visualizations of public blockchain data and simulation results that provide intuitive analytics to customers|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912480226\n",
      "\n",
      "|Productionize, launch, and monitor predictive models with high-dimensional, fast-moving real-time datasets.|Design, analyze, and manage both simulated and live experiments (A/B and multivariate tests) to drive KPI improvements.|Lead end-to-end cross functional analytics projects: scope requirements with stakeholders, collect and analyze data, as well as summarize and present key insights in support of critical decision making.|Analysis of large amounts of data to gather insights, identify trends, detect anomalies, develop key KPIs, and feed powerful dashboards and visualizations.|Build new and improve existing ML models by incorporating new sources, developing and testing model improvements, running experiments, and fine tuning parameters.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2910873146\n",
      "\n",
      " Do:|Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.|Work with large, complex data sets|Build and develop all necessary data pipelines|Develop and deploy streaming microservices that enrich the raw data with knowledge and models Develop and deploy standard evaluation frameworks|Develop and deploy per member optimization simulations across financial, clinical and experience outcome variables|Contribute to the success of the team with specific experiment and research directions that can take our guidance platform to the next level|Develop predictive and prescriptive models|Who You Are:|You have an entrepreneurial spirit|You’re able to inspire through your work and motivate others|You have the ability to be both strategic and tactical|What \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912897584\n",
      "\n",
      "We are the leaders in utilizing mass data sets and artificial intelligence to help philanthropy offices raise more money to support healthcare organizations and the patients’ they serve. As we continue to rapidly expand our efforts, we need top individuals with a passion for artificial intelligence, experience and proficiency with algorithmic design and development; specifically, in machine learning (including deep learning), and one or more of the following technical areas: decision science, human machine teaming, cognitive science, multi-agent systems, knowledge-based reasoning, automated planning, semantics, and ontologies.|You will have opportunities to work on a wide range of problems, leading and working with teams possessing a broad range of skills. Your experience will allow you to influence individuals who want to donate based on extraordinary patient experiences; evaluate the challenges and potential solutions for designing, developing, and fielding artificial intelligence solutions that inform mission-critical decisions; assess the adequacy and maturation of existing programs and shape their technical and programmatic direction; and identify new areas where giving and development are needed to strengthen the industry’s growing artificial intelligence capabilities.|Responsibilities|As a Data Scientist, you will be responsible for building, maintaining, and expanding the machine learning models that powers Gobel’s products and services. We are looking for a problem solver with an innate ability to understand customer needs, support and maintain data warehouses and ML models using artificial intelligence, and someone who willingly collaborates on related issues and innovated enhancements.|The right candidate must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building, and implementing models, using/creating algorithms, and creating/running simulations. The candidate must have a proven ability to drive business results with their data-based insights. The candidate must be comfortable working with a wide range of stakeholders and functional teams. The candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.|Partner closely with existing data scientist team members building knowledge of existing models and full-fill requests that relate to using our data warehouses.|Work on, or lead, a cross-functional team to develop and implement Al algorithms that can help solve problems that result in a transformational impact for healthcare organizations.|Apply modern engineering techniques to develop decision support software prototypes.|Propose and execute novel, cutting-edge techniques in Al-enhanced decision systems.|Evaluate existing solutions in the context client’s having the highest ROI and produce actionable recommendations.|Identify, design, and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.|Take over daily screenings and product offerings that are being delivered to clients.|Access and query a variety of data sources (relational databases, SQL databases, flat files, csvs, APIs).|Filter and transform data to dedupe records and clean the individual data fields.|Clean, prepare and optimize data at scale for ingestion and consumption.|Proactively anticipate, identify, and solve issues concerning data management to improve data quality.|Work with stakeholders including executive, data, design, product, and services teams and assisting them with data-related technical issues.|Implement automated workflows and routines using workflow scheduling tools.|Build continuous integration, test driven development and production deployment frameworks.|Work with clients (on the phone, over email, face-to-face) as needed to understand existing issues or new requirements.|Perform quality checks from business requirements to user acceptance testing.|Seek out innovate ways to enhance products and services offered.|In partnership with team, develop and maintain standardization of documents and materials.|Other duties as assigned.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2909338218\n",
      "\n",
      "|This position will support the franchises by using internal Quest Diagnostics data and externally purchased market data to inform key business decisions.The main purpose of this role is to turn data into insights that drive key decisions for the organization and our clients.|Duties and Responsibilities:|Provide biostatistical consultation to clients or colleagues.|Analyze archival data such as laboratory, medical, prescription, and death records.|Read current literature, attend meetings or conferences, and talk with colleagues to keep abreast of methodological or conceptual developments in fields such as actuarial sciences, data science, biostatistics, risk management, pharmacology, life sciences, and social sciences.|Prepare articles for publication or presentation at professional conferences.|Calculate sample size requirements for studies.|Write program code to analyze data and develop predictive models using SAS statistical analysis software.|Write detailed analysis plans and descriptions of analyses and findings for research protocols or reports.|Prepare tables and graphs to present data or results.|Draw conclusions or make predictions based on data summaries or statistical analyses.|Develop or implement data analysis and reporting algorithms.|Design research studies in collaboration with physicians, life scientists, underwriters, or other professionals.|Analyze data using statistical approaches such as longitudinal analysis, mixed effect modeling, logistic regression analyses proportional hazards regression, and other model building techniques.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912708341\n",
      "\n",
      ":|Lead a broad range of data-driven projects, from machine learning to|design and analysis|Contribute to agile development of advanced analytics projects|Work with stakeholders to identify opportunities where data and data|can be leveraged|Use scientific rigor to both create and challenge hypotheses and data in a collaborative environment|Aid in business strategy by documenting assumptions, hypothesis and related risks with respect to data products|Develop machine learning software for ultra low-cost nitrogen sensing devices|Developing ML prediction engines to curate content for farmers|Transforming crop models into production models|Developing frameworks to assess accuracy of novel hardware solutions|Predicting crop yield from third party data|Data Scientist \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2911409783\n",
      "\n",
      ":|At Coursera, our Data Science team is helping to build the future of education through data-driven decision making and data-powered products. We drive product and business strategy through measurement, experimentation, and causal inference. We define, develop, and launch the models and algorithms that power content discovery, personalized learning, and machine-assisted teaching and grading. We believe the next generation of teaching and learning should be personalized, accessible, and efficient. With our scale, data, technology, and talent, Coursera and its Data Science team are positioned to make that vision a reality.|We’re looking for a talented, creative, and collaborative data scientist to support decision-making for our product and business teams -- leveraging the rich data captured as tens of millions of learners and thousands of instructors engage on the platform to deliver innovative, data-driven insights on how to create experiences that will better meet the needs and expectations of learners. Our ideal candidate has excellent analysis and statistical modeling skills, strong written and verbal communication, and an interest in expanding the reach and quality of online education.|Responsibilities:|Evaluate the success of key product and business initiatives (e.g. determining whether new product listing pages better serve career switchers or measuring the success of efforts to reduce contact rate by improving the learner payment flow)|Estimate the potential impact of proposed projects in order to inform other teams’ prioritization decisions|Develop our understanding of Coursera’s products, business, and learners by analyzing learner behavior to uncover patterns and identify opportunities for improvement|Work closely with data engineering and operations teams to ensure that new projects and products are launched with clear instrumentation to support experimentation and measurement plans|Partner with other data scientists to develop measurement plans for new data product launches and to share context from different areas of the business and build a more complete and consistent understanding of what data tells us about our learners|Basic \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912840985\n",
      "\n",
      ":|·         Design of data science pipelines to ingest new data sources applying NLP processes to textual data, for example research abstracts and clinical trial documentation|·         Work with our existing data science team and models for research risk, peak sales predictions, and epidemiological datasets by engineering new features derived via NLP|·         Work with the broader Research & Development team to create improvements to our products and increase our data breadth and depth|·         Work with the data engineers to deploy new and existing models in AWS, suitable for production environments|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2908517430\n",
      "\n",
      "|Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the operations and R&D teams to strategize and execute the development of data products|Execute analytical experiments methodically to help solve various problems and make a true impact across the industry|Identify relevant data sources and sets to mine for customer’s business needs, and collect large structured and unstructured datasets and variables|Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy|Create validation models and limits to be implemented into database|Analyze data for trends and patterns, and interpret data with a clear objective in mind|Implement analytical models into production by collaborating with software developers|Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems|Skills and \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2901212301\n",
      "\n",
      "|Analyze raw data: assessing quality, cleansing, structuring for downstream processing|Design accurate and scalable prediction algorithms|Collaborate with engineering team to bring analytical prototypes to production|Generate actionable insights for business improvements|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2911271258\n",
      "\n",
      " & Responsibilities|This role will be tasked with applying machine learning/deep learning to the automotive industry. Applications could include autonomous driving, manufacturing, material design etc. This is more than a purely academic role – you will likely need to integrate the modules you build into real cars and also think about questions around testability and proving safety.|Major tasks include and not limited to:|- Evaluate cutting edge AI/ML method and techniques|- Build functional SW prototypes|- Document and present the milestones and deliverables|Education and Skills \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2904096931\n",
      "\n",
      " of the Data Scientist include:|Implement models for loan loss allowance, CECL, stress testing, new volume origination, line of credit utilization, and prepayment models for all products, including credit card, personal loan, student loan, auto loan, mortgage, and commercial loan.|Maintaining documentation for key processes and model components across the team with a focus on standardization of processes that satisfy model risk management, audit, and regulatory requirements.|Implement vendor-developed models for consumer and commercial credit loss or prepayment.|Monitor performance of quantitative models and support independent model validation efforts in accordance with the model risk management policy.|Establish and document model implementation controls that satisfy model risk management, audit, and regulatory requirements.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912744296\n",
      "\n",
      "|WhirlWind is on a mission to help each client succeed by using our management consulting and technology expertise. We design, build, and manage secure environments that support data-driven decision making and data-powered products. Our services transform governments and enhance the lives of citizens.|Our people are driven and committed to our mission. If you want to join a team of rock stars who do incredible, purposeful work, and have fun doing it, come thrive with us and be one of the heroes behind our success. We offer an attractive benefits package including a competitive base salary and have been voted the Best Place to Work for 2021.|Position Overview|WhirlWind Technologies is seeking a Data Scientist to support a client-facing project in|Suitland, MD.|The candidate will serve as a Data Scientist.|Top 3 Outcomes in Year 1|With your leadership and technical skills, achieve a state-of-the-art, highly automated, and interactive data visualization system|Lead and obtain organic growth of the current IT contract and client account|Achieve and/or increase customer satisfaction through mutually agreeable performance metrics|Essential Duties & Responsibilities|Develop methods and procedures for collection and analysis of data from several data sources|Monitor, review, and validate customer data is collected and processed on schedule|Automate data collection from various external data sources and data type|Lead requirements gathering from customer and stakeholders and create interactive data visualization dashboards that meet or exceed customer requirements and expectations|Identify and integrate tools to enhance data visualization efficiencies and effectiveness such as machine learning (ML), artificial intelligence (AI), and robotics process automation (RPA)|Proactively seek an understanding of the customer’s business, mission, and vision to provide additional thought leadership to achieve their goals.|Create clear and concise presentations as needed to communicate with the customer and stakeholders the status of projects and assigned tasks|Provide weekly written status reports and brief customer weekly on the status of the project activities|Required \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2911250669\n",
      "\n",
      ":|Perform exploratory analysis and cleaning on high-frequency physiological monitoring data|Leverage techniques from time series analysis and signal processing to build and test algorithm prototypes|Deploy and monitor algorithms in digital health products, ensuring real-world performance is as expected|Summarize and communicate findings and results to technical and non-technical audiences|Develop subject-matter expertise at the intersection of clinical and technical areas|Minimum Experience, Skills, and \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2911419822\n",
      "\n",
      ":|Train and evaluate machine learning models, including deep neural networks, which resolve the technical issues of installing and operating cellular networks. Implement prototypes and production-ready scalable solutions based on machine learning technologies. Conduct functional and technical analysis within Ericsson organization and with strategic customers to understand (Machine Intelligence) MI-driven business needs and opportunities. Contribute to rapid and iterative development of validated minimum viable solution addressing these needs. Work with petabytes of 4G/5G-networks and IoT and exogenous data. Propose, select, and test predictive models, recommendation engines, anomaly detection systems, statistical models, deep learning, reinforcement learning, and other machine learning systems. Conduct studies and find creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones, as needed. Collaborate with product development teams and partners in Ericsson businesses to industrialize machine learning models and solutions as part of Ericsson offerings to include providing source code, workflows, and documents. Work with new technologies and champion them in MI communities within Ericsson. Assist MI competence build-up in Ericsson businesses and customer serving units. Help to develop and apply/extend new concepts, methodologies, techniques for cross-functional initiatives. Engage with the external ecosystem (academia, technology leaders, open-source, etc.) to develop the skills and technology portfolio for MIs needs. Implement new algorithms and methodologies from leading open source initiatives and research papers addressing their functionalities, scalability, and overall industrialization viability. Understand, design, and develop Heuristics and/or machine learning algorithms with telecom network configuration related datasets. Find relevant metrics and measurements for evaluating model performance based on the established success criteria. Conduct customer/stakeholder interviews to arrive at problem definition and value proposition. Demonstrate data findings and communicate research results. Create methodology documents, case reviews, and closure documentation. Perform Agile life cycle methodology. Interact with fellow Data Scientists, write research papers/blogs, and enable a learning environment in the workplace.|Job \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2904389147\n",
      "\n",
      "|Writing and configuring machine learning pipelines|Identifying/defining business problems and creating solutions using machine learning models and statistics|Managing tasks independently and within your team to meet business objectives|Validating and deploying new machine models and statistical reports|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2906913218\n",
      "\n",
      "1st shift (United States of America)|Please Review The Following Job Description|Perform sophisticated analytics (statistical and predictive analytics, machine learning modeling, etc.) to provide actionable insights that improve business outcomes and minimize risk and also provide consultation to business leaders and other stakeholders on how to leverage analytics insights and build strategies around analytics.|Following is a summary of the essential functions for this job. Other duties may be performed, both major and minor, which are not mentioned below. Specific activities may change from time to time.|Independently perform sophisticated data analytics (ranging from classical econometrics to machine learning, neural networks, and natural language processing) in a variety of environments using structured and unstructured data.|Produce compelling data visualizations to communicate insights and influence outcomes among a wide array of stakeholders.|Take accountability and ownership of end-to-end data science solution design, technical delivery, and measurable business outcome.|Engage in stakeholder meetings to identify business objectives and scope solution requirements.|With minimal guidance, write, document, and deploy custom code in a variety of environments (Python, SAS, R, etc.) to create predictive analytics applications.|Use, maintain, share and collaborate through Truist internal code repositories to foster continual learning and cross-pollination of skillsets.|Actively research and advocate adoption of emerging methods and technologies in the data science field, with the eye of continually advancing Truist’s capabilities.|Exercise sound judgment and fosters risk management culture throughout design, development, and deployment practices; partner with cross-functional teams to coordinate rules on data usage, data governance and analytics capabilities.|Required \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2909581057\n",
      "\n",
      " required for this position. It is not intended to serve as an exhaustive list of duties, skills, and responsibilities.|Summary:|Working in collaboration with the Management team, the Data Scientist provides support by creating reports/dashboards of clinical, operational, and financial data for all company locations. The ideal individual will have the ability to exercise good judgment in a variety of situations, with strong written and verbal communication, administrative, time management, and organizational skills and the ability to maintain a realistic balance among multiple priorities. The Data Scientist will have the ability to work independently and in a team setting and must be able to work under pressure at all times to handle a wide variety of activities and confidential matters.|Responsibilities|Create custom reports and presentations accompanied by strong data visualization and storytelling|Present analytical conclusions to senior officials in the company and other stakeholders|Maintain patient data safety and confidentiality|Maintaining data integrity and security|Transforming or transferring data upon request|Performing data requests in a timely manner|Preparing data for meetings and presentation|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2906743970\n",
      "\n",
      "|Understand, develop, and deploy data science solutions for network security in conjunction with the threat research and engineering teams.|Evaluate and suggest improvements to existing models and data-driven detections|Participate in daily engineering meetings (company-internal)|Document and report individual work efforts using Jira tickets|Essential \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2911263612\n",
      "\n",
      " of this position include, but are not limited to:|Under the limited supervision of the Supervising Discipline Scientist, may perform technical assignments of various complexities within approved scientific schedules and budgets.|May coordinate technical and administrative activities with employees in other disciplines and other departments participating on an assigned project.|May assist in the training and evaluation of assigned scientific personnel.|Provide innovative digital solutions using predictive learning and machine learning.|Work under general supervision to develop end-to-end data science solutions through tasks including data wrangling, exploratory analysis, transformations, dimensionality reduction, assessments, visualizations, and similar tasks.|Develop innovative solutions that leverage data science to improve business workflows/deliverables and allow for data-driven decision-making.|Communicate complex quantitative analysis in a clear, precise, and actionable manner using storytelling / visualization.|Stay on the forefront of novel data sciences tools, solutions, and concepts in the machine learning space.|Generate technical documentation describing developed data science solutions and training staff to employ those solutions.|Work with both non-geospatial and geospatial data.|Under the limited supervision of the Supervising Discipline Scientist, may perform technical assignments of various complexities within approved scientific schedules and budgets.|At AECOM, we’re delivering a better world.|We believe infrastructure creates opportunity for everyone. Whether it’s improving your commute, keeping the lights on, providing access to clean water or transforming skylines, our work helps people and communities thrive.|Our clients trust us to bring together the best people, ideas, technical expertise and digital solutions to our work in transportation, buildings, water, the environment and new energy. We’re one global team – 47,000 strong – driven by a common purpose to deliver a better world.|Minimum \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2906495306\n",
      "\n",
      "|Development and maintenance of commercial analytics data models.|Deep insights into customer needs and preferences leverage both structured and non-structed data building segmentation models that are actionable by the business.|Deep insights into the market and Signature’s position across multiple dimensions of brand, service levels, pricing and cost.|Leverage prescriptive and predictive modeling to optimize customer experiences, revenue generation, product offerings, and other business outcomes.|Provide support and guidance to the commercial function in the areas of – statistical modeling, customer segmentation, pricing analytics, causal inference models, demand forecasting, marketing analytics, qualitative models, market research, econometric models, decision trees, classification models and presentation of insights.|Build and operationalize complex data solutions, data pipelines, and processes for the commercial team to easily access data for analysis and reporting.|Automation of data processes on cloud and on premise to ensure secure, supported, and scalable solutions.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2907324921\n",
      "\n",
      " Do|Clarkston gives you the opportunity to deliver great solutions, become recognized as an industry expert, and help build a great practice.|As a Data Scientist at Clarkston, you will:|Conduct exploratory analysis, produce descriptive statistics and explain phenomena based on data|Develop statistical and machine learning models for POC and production-ready applications|Drive ideation and execution of experiments and in-market tests with an eye on accuracy and statistical significance|Provide coaching and mentorship to junior analysts who are developing their skills|How You’ll Grow|At Clarkston, we feel that we provide the greatest value to our clients through a combination of our industry expertise, business process knowledge, and consulting excellence.|Beyond your day-to-day responsibilities, throughout your career at Clarkston you will:|Have the support and mentorship of your Clarkston colleagues and leaders|Own your career – you'll be able to take charge of your career journey with diverse opportunities to lead and expand your skillset both at the client site and within the firm|Have the opportunity to make a real and positive impact not only the clients you work with, but on the firm as well|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2909266017\n",
      "\n",
      "|Contribute to the success of the data science team|Develop new algorithms or delivering customer solutions for assigned projects|Collaborate with internal, external, and/or client-based Data Scientist, Data Engineers, Analysts and/or Business functions to understand the Analytic Mission and deliver high-performance algorithmic-based solutions|Complete ad-hoc analysis and ability to present results in a clear manner to both internal and external stakeholders|Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.|Collaborate to help extend the company’s data with third party sources of information when needed|Develop custom data models and algorithms to apply to data sets.|Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.|Coordinate with different functional teams to implement models and monitor outcomes.|Contribute to the development processes and tools to monitor and analyze model performance and data accuracy.|Skills And \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2904630406\n",
      "\n",
      "|Continuously explore new alternative data sources to add incremental predictiveness in the models though orthogonal signals/features.|Build end to end machine learning models, from design, learning, evaluation, validation & monitoring.|Create, expand, explore, rank & maintain logs of innovative internal feature sets for credit, pricing & fraud.|Expand the performance data using organic & synthetic methods wherever possible.|Develop automation capabilities & advanced dashboards required for faster processing and monitoring.|Own end to end model implementation, model iteration, model versioning, for production and sandbox environment.|Collaborate with the engineering and product teams to implement, ship, test and monitor the risk models.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2889573430\n",
      "\n",
      " Do|Help deliver supply chain optimization projects, with the direction of more senior data scientists, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models with monitoring.|Use ML platforms (AWS SageMaker), and tools (e.g., scikit-learn, numpy, pandas) to help us build ML models.|Research and implement novel ML approaches.|Work with business and engineering teams to analyze, extract, normalize, and label relevant data.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2885217272\n",
      "\n",
      "|Work with stakeholders to take a vague problem statement, refine the scope of the analysis, and use the results to drive informed decisions|Write reproducible data analysis over petabytes of data using cutting-edge open source technologies|Summarize and clearly communicate data analysis assumptions and results|Build data pipelines to promote your ad-hoc data analyses into production dashboards that engineers can rely on|Design and implement metrics, applications and tools that will enable engineers by allowing them to self-serve their data insights|Work with engineers to drive usage of your applications and tools|Write clean and tested code that can be maintained and extended by other software engineers|Operate and support your production applications|Keep up to date on relevant technologies and frameworks, and propose new ones that the team could leverage|Identify trends, invent new ways of looking at data, and get creative in order to drive improvements in both existing and future products|Give talks, contribute to open source projects, and advance data science on a global scale|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2892288873\n",
      "\n",
      " as assigned.|Physical Actions|Sits or stands for extended periods of time, up to a full work shift. Occasionally reaches overhead and below the knees, including bending, twisting, pulling, and stooping. Occasionally moves, lifts, carries, and places objects and supplies weighing 0-10 pounds without assistance. Listens to, interprets, and differentiates auditory information (e.g. others speaking) at normal speaking levels with or without correction. Visually verifies and reads information. Visually locates material, resources and other objects. Ability to operate a computer for extended periods of time, up to a full work shift. Physical dexterity sufficient to use hands, arms, and shoulders repetitively to operate keyboard and other office equipment up to a full work shift.|Physical Environment|This position operates in an open office working environment which will include normal and customary distractions, noise, and interruptions.|Education \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2892287978\n",
      "\n",
      " as assigned.|Physical Actions|Sits or stands for extended periods of time, up to a full work shift. Occasionally reaches overhead and below the knees, including bending, twisting, pulling, and stooping. Occasionally moves, lifts, carries, and places objects and supplies weighing 0-10 pounds without assistance. Listens to, interprets, and differentiates auditory information (e.g. others speaking) at normal speaking levels with or without correction. Visually verifies and reads information. Visually locates material, resources and other objects. Ability to operate a computer for extended periods of time, up to a full work shift. Physical dexterity sufficient to use hands, arms, and shoulders repetitively to operate keyboard and other office equipment up to a full work shift.|Physical Environment|This position operates in an open office working environment which will include normal and customary distractions, noise, and interruptions.|Education \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912282652\n",
      "\n",
      "|AIR is currently seeking a|Data Scientist Associate|to join our Data Science and Advanced Analytics (DSAA) group. DSAA employs advanced analytics methods to solve complex research questions and address public policy questions to support evidence-based decision-making to solve complex social problems. Candidates hired for the position might initially start working remotely but will eventually have the option to work from our Arlington, VA office or continue to work remotely.|Do you want to work for a mission-focused and exciting institution? T hen come join us. AIR is AIR is a nonpartisan, not-for-profit institution that conducts behavioral and social science research and delivers technical assistance to solve some of the most urgent challenges in the U.S. and around the world. We advance evidence in the areas of education, health, the workforce, human services, and international development to create a better, more equitable world. We do this work because when we look to the future, we see opportunities to close gaps that are rooted in injustice. At AIR, we know that equity begins with systems that work for everyone, so we lead with expertise, follow the evidence, and never stop drawing new connections to build a better, more equitable world.|Data Scientists at AIR use a blend of technology skills and theory to contribute to cutting-edge research design, implementation, and capacity building. Our team promotes data scientists’ career development through interdisciplinary collaboration, training opportunities, a community of practice, mentorship and managerial responsibilities, and the opportunity to work on meaningful projects spanning several domains, including education, public health, workforce, science and innovation policy, criminal justice, and housing. We balance contemporary agile development with rigorous approaches to research design, all the while remaining outcomes-driven and aligned to our clients’ missions and goals.|Responsibilities|The responsibilities for the position include:|Support efforts to collect, compile, validate, interpret, and analyze data using standard practices and techniques|Support computer modeling or simple to moderately complex forecasting using standard software packages|Support to quantitative and/or qualitative analysis using standard techniques and methods|Work independently and in teams on moderately complex assignments under indirect supervision|Create replicable, well-annotated code in a shared environment|Coordinate project support needs and requests for senior management and clientele|Conduct literature reviews and write sections of proposals and deliverables|Develop systems for maintaining and checking the accuracy of data for assigned projects|Utilize external resources to supplement, organize, and contribute to tasks and projects|Present and occasionally support and organize content in internal and external meetings|Remain up-to-date on and provide suggestions for new technologies that can be used in research|Review and optimize others’ programming code|Provide innovative and suitable solutions to complex problems|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2892285984\n",
      "\n",
      " as assigned.|Physical Actions|Sits or stands for extended periods of time, up to a full work shift. Occasionally reaches overhead and below the knees, including bending, twisting, pulling, and stooping. Occasionally moves, lifts, carries, and places objects and supplies weighing 0-10 pounds without assistance. Listens to, interprets, and differentiates auditory information (e.g. others speaking) at normal speaking levels with or without correction. Visually verifies and reads information. Visually locates material, resources and other objects. Ability to operate a computer for extended periods of time, up to a full work shift. Physical dexterity sufficient to use hands, arms, and shoulders repetitively to operate keyboard and other office equipment up to a full work shift.|Physical Environment|This position operates in an open office working environment which will include normal and customary distractions, noise, and interruptions.|Education \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2910579865\n",
      "\n",
      "Are you passionate about making the internet safer, more inclusive, and more enjoyable for people around the world? As a Data Scientist on the Community Health team at Twitch, you'll play a central role in the design and deployment of products that support the safety of millions of Twitch users. You will be part of a growing organization that builds the tools which help communities self-moderate, improves our reporting and enforcement processes, and builds automated machine learning models that serve as the first line of defense against harmful behaviors.|You will specifically lead research in areas such as (1) quantifying the prevalence of harmful actions across the service and (2) estimating the impact of new features on our viewers and creators, often in scenarios where traditional randomized controlled experiments are not possible. You will design research projects that help build our knowledge of how to keep communities safe, and leverage this expertise to guide strategy around the company. You will report to the Head of Science for Community Health. We are based in San Francisco, however we're open to you working out of our Seattle, WA, Irvine, CA, or Salt Lake City, UT offices.|You'll find a \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2893144934\n",
      "\n",
      "|Deliver scalable, production-ready code|SQL development, use of analytics tools, operate in AWS environment|Participate in sprints and scrum meetings, close collaboration with product owner|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2909000319\n",
      "\n",
      "The Workplace Investing AI Delivery Engineering Chapter team is seeking a Principal Data Engineer / Tech lead to design, implement and improve technical solutions for AI|model deployment, data pipelines, hosting and API access tiers in support of the Intelligent Automation AI Product Area. We are looking for an outspoken technologist|with a deep passion for data and application design to help build AWS-based AI solutions to help extract data from both databases and unstructured data sources and harness AI|algorithms to help automate difficult business problems facing our Workplace operations team. This role will be a great mix of peer mentorship, technical leadership,|application, API and data pipeline design, and lots of hands-on work along with partnering with our data scientists and business.|The Expertise and \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2892291600\n",
      "\n",
      " as assigned.|Physical Actions|Sits or stands for extended periods of time, up to a full work shift. Occasionally reaches overhead and below the knees, including bending, twisting, pulling, and stooping. Occasionally moves, lifts, carries, and places objects and supplies weighing 0-10 pounds without assistance. Listens to, interprets, and differentiates auditory information (e.g. others speaking) at normal speaking levels with or without correction. Visually verifies and reads information. Visually locates material, resources and other objects. Ability to operate a computer for extended periods of time, up to a full work shift. Physical dexterity sufficient to use hands, arms, and shoulders repetitively to operate keyboard and other office equipment up to a full work shift.|Physical Environment|This position operates in an open office working environment which will include normal and customary distractions, noise, and interruptions.|Education \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2892287977\n",
      "\n",
      " as assigned.|Physical Actions|Sits or stands for extended periods of time, up to a full work shift. Occasionally reaches overhead and below the knees, including bending, twisting, pulling, and stooping. Occasionally moves, lifts, carries, and places objects and supplies weighing 0-10 pounds without assistance. Listens to, interprets, and differentiates auditory information (e.g. others speaking) at normal speaking levels with or without correction. Visually verifies and reads information. Visually locates material, resources and other objects. Ability to operate a computer for extended periods of time, up to a full work shift. Physical dexterity sufficient to use hands, arms, and shoulders repetitively to operate keyboard and other office equipment up to a full work shift.|Physical Environment|This position operates in an open office working environment which will include normal and customary distractions, noise, and interruptions.|Education \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2889854773\n",
      "\n",
      " and Responsibilities|Work closely with the heads of Data Science and Advisory to appropriately translate our clients’ business needs into an analytical framework that BERA’s data and tools can support at-scale|Own the full lifecycle of model development from ideation and data exploration, algorithm design and testing, algorithm development and deployment, to algorithm monitoring and tuning in production.|Develop prototypes for visualizing model results and key insights|Document methodology, code and process for ML solutions so that others in the organization (e.g., Engineering) can understand the model and leverage it for their own uses|Partner closely with BERA product and engineering teams to implement ML into customer facing BERA SaaS products|Support BERA sales, marketing, customer success and advisory teams with advanced analytics to assist in new business development, client retention and client expansion|Identify opportunities to advance and optimize BERA's current product offerings with ML applications|Assist in automation and monitoring of data quality and veracity checks|Experience and \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2892291602\n",
      "\n",
      " as assigned.|Physical Actions|Sits or stands for extended periods of time, up to a full work shift. Occasionally reaches overhead and below the knees, including bending, twisting, pulling, and stooping. Occasionally moves, lifts, carries, and places objects and supplies weighing 0-10 pounds without assistance. Listens to, interprets, and differentiates auditory information (e.g. others speaking) at normal speaking levels with or without correction. Visually verifies and reads information. Visually locates material, resources and other objects. Ability to operate a computer for extended periods of time, up to a full work shift. Physical dexterity sufficient to use hands, arms, and shoulders repetitively to operate keyboard and other office equipment up to a full work shift.|Physical Environment|This position operates in an open office working environment which will include normal and customary distractions, noise, and interruptions.|Education \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2886523110\n",
      "\n",
      "Data is central to Twitch's decision-making process, and data scientists are a critical component to evangelize data-driven decision-making in all of our operations. As an data scientist at Twitch, you will be on the ground floor with your team, shaping the way product performance is measured, defining what questions should be asked, and scaling analytics methods and tools to support our growing business, leading the way for high-quality, high velocity decisions for your team.|For this role, we're looking for an experienced data scientist in analytics who will help develop the strategy and evaluate/improve product initiatives within our Community Experiences product team. You will be responsible to define and track KPIs, design experiments, evaluate A/B tests, implement data instrumentation, and inform on investment. Our ideal candidate is a \"full-stack\" data powerhouse who uses data to drive decision-making to make the best products for our creators and their communities. Your input will be core to decision-making across all major product strategies and initiatives that our team builds. You will work with product managers, technical program managers, engineering, data scientists, and organization leadership within and outside of the Community organization.|You Will:|Inform product strategies by defining and updating core metrics for each initiative|Establish analytical framework for your team: ad-hoc analysis, automated dashboards, and self-service reporting tools to surface key data to stakeholders|Evaluate and forecast impact of product features on creators, viewers, and the entire Twitch ecosystem|Design A/B experiments to drive product direction with iterative innovation and measurement|Drive the team's analysis roadmap and prioritize the most valuable projects|Dive deep into the data to understand how creator and viewer behaviors change with the evolution of our product|Act as our team's thought leader on best practices and move towards long-term vision of sustainable and thriving data processes|Own data collection and product instrumentation implementation and quality assurance|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912219422\n",
      "\n",
      "This individual will lead high profile data science and artificial intelligence projects working closely with Technology, Product Management, Call Center, and others across multiple business units and teams to define and develop AI-based solutions. Candidate must be comfortable in a fast-paced, unpredictable and sometimes ambiguous environment working with current and emerging AI technologies. The assignments will include gathering data from multiple sources, data processing, exploratory data analysis, measurement, unstructured data analysis, predictive analytics, prescriptive analytics, interpretation of findings, presentation, and system implementation.|The successful candidate will be capable of supporting projects across many areas with the highest degree of quality. They will have a proven record of assuring quality of data gathering and analysis, be a great teammate who thrives in a hard-working work environment and acts with confidence to communicate to all levels of Workplace Investing and the Fidelity Enterprise|The Expertise And \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912440082\n",
      "\n",
      "|We are not just offering a job but a meaningful career! Come join our passionate team!|As a Fortune 50 company, we hire the best employees to serve our customers, making us a leader in the insurance and financial services industry. State Farm embraces diversity and inclusion to ensure a workforce that is engaged, builds on the strengths and talents of all associates, and creates a Good Neighbor culture.|We offer competitive benefits and pay with the potential for an annual financial award based on both individual and enterprise performance. Our employees have an opportunity to participate in volunteer events within the community and engage in a learning culture. We offer programs to assist with tuition reimbursement, professional designations, employee development, wellness initiatives, and more!|Visit our Careers page for more information on our benefits , locations and the process of joining the State Farm team!|Responsibilities|As a data scientist at State Farm, you will help business partners build advanced analytic solutions to help drive results for the enterprise. You will serve not just as a subject matter expert and consultant, but also as a teacher. Through this role, you will work to increase the use of analytics for decision making across the company.|Why Join Our Team:|Being part of our data science team will help facilitate your professional growth across multiple development areas. First, you will strengthen your communication skills through interactions with business partners that require you to articulate statistical concepts in a non-technical way. Additionally, the variety of projects that you work on will allow you to refine your knowledge for supervised and unsupervised learning techniques. Finally, the landscape of the data science field is quickly changing, so this role includes an opportunity for practical research which equates to unbounded development opportunities for your analytic skills.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2892366433\n",
      "\n",
      "|Analyze raw data: assessing quality, cleansing, structuring for downstream processing|Design accurate and scalable prediction algorithms|Collaborate with engineering team to bring analytical prototypes to production|Generate actionable insights for business improvements|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2893706900\n",
      "\n",
      " Do...|Walmart Global Tech CSIS (Core Services: Item and Supply Chain Technology) Data Science team is looking for a passionate data scientist to join world’s largest retailer to shape the future of retail by working on various Mid-Mile and Last-Mile related problems. You will have the chance to leverage advanced machine learning and optimization methods to tackle a wide range of real-world problems, such as driver-trip matching, trip pricing, supply/demand forecast and time prediction, driver workload matching, mid-mile loading and so on.|What You’ll Achieve|Collaborate with stakeholders, including product, engineering, operations team to ensure that our data science product supports Walmart’s business objectives|Build data pipeline from multiple sources and extract data insight with data exploration and visualization techniques|Implement, productionize and deploy data science products with consideration of optimality and computation complexity|About You|Solid knowledge in advanced optimization algorithms including mixed integer programming models, network flows models, heuristics, meta-heuristics and etc.|knowledge in developing flexible models based on Vehicle Routing, Scheduling and Graph Theory to solve for challenging combinatorial optimization problems.|Passionate about building scalable, reliable data driver products|Ability to write production grade code in programming languages, such as Python, R and Java, with understanding of algorithms and data structures|Experience with SQL|Ability to translate business needs into analytical frameworks|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2910868329\n",
      "\n",
      "|Develop, design, build, and oversee data science solutions to provide predictive insights that further McKesson’s vision to improve care in every setting — one product, one partner, one patient at a time.|Collaborate with multi-disciplinary team members; Manage business stakeholder relationships to drive action and value from data science insights.|Provide guidance to a team, largely comprised of analysts, on implementing machine learning capabilities into their deliverables.|Provide analytics leadership; conduct methodology and code reviews; utilize industry and academic resources to continuously learn and contribute to a growing knowledge base of data science best practices.|Develop comprehensive understanding of McKesson’s data environment to design data strategy for use in machine learning models; analyze complex health, business transaction, and supply chain datasets|Understand problems from the business point of view, build and execute solid analytics work plans, gather and organize large and complex data assets, perform relevant analyses (data exploration and statistical modeling), automate work streams, foster teamwork in interactions, develop client relationships with business stakeholders, and communicate hypotheses and findings in a structured way.|Communicate results; develop and maintain strong relationships with key stakeholders, partners and internal clients.|Minimum \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2892018370\n",
      "\n",
      " Do:|With minimal guidance, use advanced statistical and computational methodologies to deliver customer and promotional related insights and recommendations for business teams and leaders|Identify ways to use data science techniques to derive useful insights that can be incorporated into existing workflows and processes to enhance business results|Evaluate existing and new data sources and apply the right analytical techniques to generate significant insights about customers, products and the business|Ability to present findings in simple way to help inform and enable business decisions|Ability to implement data science applications in a general programming language such as Python or R|Proficiency in employing large scale data analytics to derive actionable insights|Ability to interface and collaborate with technical and non-technical team members to accomplish goals|Use quantitative skills to work on a variety of research and analysis projects|Ad-hoc analyses as required|Required \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2910843109\n",
      "\n",
      " Do|We are seeking a Data Scientist to join our team to develop an insight driven sensing capability with a focus on revolutionizing decision making. As part of this role you will be solving big data problems and developing insights as part of a product team of data scientists, business analysts, and software engineers. The team will rely on your expertise in data science to build this visionary new capability for Amgen.|Build supervised and unsupervised algorithms to provide meaningful insights across Amgen’s value chain (R&D, Commercial, Operations)|Work closely with machine learning engineers to develop production code and deliver end-to-end solutions|Transform ambiguous business questions into measurable and impactful projects|Collaborate cross-functionally with teams of biologists, clinical experts, doctors, and commercial leads|Translate complex problems and solutions and provide actionable insight to executives|Serve as technical lead on projects and mentor junior and experienced data scientists|Help further build the team, including contributing ideas, establishing best practices, following trends in industry and academia|Basic \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2891165676\n",
      "\n",
      " Work On|Explore, visualize, and validate our proprietary cryptocurrency data sets|Use our data and analytics tools to help some of the largest token-issuers optimize their decision-making|Collaborate with our developers to source, research, test, and analyze new data sets to include in our suite of products|Interface with our research team to write and contribute to research reports, media outlets, and other publications|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2910523582\n",
      "\n",
      "|Duties include but are not limited to:|Understand business stakeholders' needs and translate those into a data insights program with solutions for each stakeholder|Deliver on data analytics and insights by planning and performing end-to-end analysis: including aggregating and processing data, exploring data, building and validating predictive models, and presenting to business|Analyze our existing data model/structure and provide recommendations to the Tech team for optimization to support our data strategy|Design and implement statistical algorithms and predictive analysis|Explain data analytics and data science findings and machine learning models to internal and external stakeholders|Work with Data Analysts, Product Managers and Software Engineers to gather data insight requirements, set goals and influence the product roadmap|Minimum \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912463465\n",
      "\n",
      "|Performs data mining and data cleansing tasks.|Prepare datasets for modeling through balancing and validation.|Produces predictive models which enable the creation of rating plans and evaluation of risk.|Assists decision makers with studies that evaluate new business models to evaluate customers’ profitability including customers and/or risk segmentation, retention and lifetime value modeling.|Communicates to diverse audiences, including technical and non-technical.|Manages projects of moderate complexity.|Supports modeling requests made by other departments.|Works closely with others to gain strong understanding of insurance concepts and processes.|Perform other job-related duties as assigned.|\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for key, value in job_responsibilities.items():\n",
    "    # if (counter > 0):\n",
    "    print(\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/\" + key + \"\\n\")\n",
    "    print(value)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    counter += 1\n",
    "    if (counter > 50) :\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "1332"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_responsibilities)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "18"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# short_count = 0\n",
    "#\n",
    "# for key, value in job_responsibilities.items():\n",
    "#     if len(value) < 75:\n",
    "#         short_count +=1\n",
    "#\n",
    "# short_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  description\n2908496770  :|•\\tDesign and implement ML methods on propri...\n2911267267  :|• Provide consultative support as and when r...\n2912844894  :|Support Data and Analytics team through deve...\n2911205495  |Build agent-based simulations of smart contra...\n2912480226  |Productionize, launch, and monitor predictive...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2908496770</th>\n      <td>:|•\\tDesign and implement ML methods on propri...</td>\n    </tr>\n    <tr>\n      <th>2911267267</th>\n      <td>:|• Provide consultative support as and when r...</td>\n    </tr>\n    <tr>\n      <th>2912844894</th>\n      <td>:|Support Data and Analytics team through deve...</td>\n    </tr>\n    <tr>\n      <th>2911205495</th>\n      <td>|Build agent-based simulations of smart contra...</td>\n    </tr>\n    <tr>\n      <th>2912480226</th>\n      <td>|Productionize, launch, and monitor predictive...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(job_responsibilities, columns=[\"description\"], orient='index')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(1332, 1)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "df2 = df.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(1063, 1)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "df2.to_pickle('responsibilities_df_1.pickle')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}