{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: corextopic in /Users/william.bell/opt/anaconda3/envs/metis/lib/python3.8/site-packages (1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install corextopic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from corextopic import corextopic as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             responsibilities           title  \\\n2908496770  :|•\\tDesign and implement ML methods on propri...  Data Scientist   \n2911267267  :|• Provide consultative support as and when r...  Data Scientist   \n2912844894  :|Support Data and Analytics team through deve...  Data Scientist   \n2911205495  |Build agent-based simulations of smart contra...  Data Scientist   \n2912480226  |Productionize, launch, and monitor predictive...  Data Scientist   \n\n                                                  description  \\\n2908496770  <html><body><div class=\"description__text desc...   \n2911267267  <html><body><div class=\"description__text desc...   \n2912844894  <html><body><div class=\"description__text desc...   \n2911205495  <html><body><div class=\"description__text desc...   \n2912480226  <html><body><div class=\"description__text desc...   \n\n                companyName                location   level  \n2908496770  Data Revolution  San Francisco Bay Area  senior  \n2911267267       TrueSkilla           United States  senior  \n2912844894   Project Canary              Denver, CO     mid  \n2911205495         Gauntlet           United States     mid  \n2912480226            Miles        Redwood City, CA     mid  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>responsibilities</th>\n      <th>title</th>\n      <th>description</th>\n      <th>companyName</th>\n      <th>location</th>\n      <th>level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2908496770</th>\n      <td>:|•\\tDesign and implement ML methods on propri...</td>\n      <td>Data Scientist</td>\n      <td>&lt;html&gt;&lt;body&gt;&lt;div class=\"description__text desc...</td>\n      <td>Data Revolution</td>\n      <td>San Francisco Bay Area</td>\n      <td>senior</td>\n    </tr>\n    <tr>\n      <th>2911267267</th>\n      <td>:|• Provide consultative support as and when r...</td>\n      <td>Data Scientist</td>\n      <td>&lt;html&gt;&lt;body&gt;&lt;div class=\"description__text desc...</td>\n      <td>TrueSkilla</td>\n      <td>United States</td>\n      <td>senior</td>\n    </tr>\n    <tr>\n      <th>2912844894</th>\n      <td>:|Support Data and Analytics team through deve...</td>\n      <td>Data Scientist</td>\n      <td>&lt;html&gt;&lt;body&gt;&lt;div class=\"description__text desc...</td>\n      <td>Project Canary</td>\n      <td>Denver, CO</td>\n      <td>mid</td>\n    </tr>\n    <tr>\n      <th>2911205495</th>\n      <td>|Build agent-based simulations of smart contra...</td>\n      <td>Data Scientist</td>\n      <td>&lt;html&gt;&lt;body&gt;&lt;div class=\"description__text desc...</td>\n      <td>Gauntlet</td>\n      <td>United States</td>\n      <td>mid</td>\n    </tr>\n    <tr>\n      <th>2912480226</th>\n      <td>|Productionize, launch, and monitor predictive...</td>\n      <td>Data Scientist</td>\n      <td>&lt;html&gt;&lt;body&gt;&lt;div class=\"description__text desc...</td>\n      <td>Miles</td>\n      <td>Redwood City, CA</td>\n      <td>mid</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"./big_job_df.pickle\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "                            # max_features=2500,\n",
    "                             stop_words='english',\n",
    "                             token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                             binary=True)\n",
    "\n",
    "doc_word = vectorizer.fit_transform(df.responsibilities)\n",
    "words = list(np.asarray(vectorizer.get_feature_names()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "(3850, 12452)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "['aa',\n 'aaa',\n 'aalipour',\n 'ab',\n 'aba',\n 'abbott',\n 'abbvie',\n 'abbviersquos',\n 'abc',\n 'abide']"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "topic_model = ct.Corex(n_hidden= 5, ### YOUR NUMBER OF TOPICS HERE\n",
    "                       words=words,  ### YOUR VOCABULARY HERE\n",
    "                       seed=1\n",
    "                       )\n",
    "\n",
    "topic_model.fit(doc_word,          ### YOUR DOCUMENT TERM MATRIX HERE\n",
    "                words= words,      ### YOUR VOCABULARY HERE\n",
    "                docs= df.responsibilities  ### YOUR DOCUMENT SERIES HERE\n",
    "                );"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: opportunity, role, team, scientist, working, join, ll, world, people, environment\n",
      "1: develops, provides, information, performs, position, responsibilities, national, duties, assigned, applies\n",
      "2: business, insights, analytics, recommendations, opportunities, analysis, drive, identify, analytical, statistical\n",
      "3: experience, python, years, degree, sql, ability, communication, computer, skills, programming\n",
      "4: learning, machine, engineers, production, ml, problems, models, best, software, build\n"
     ]
    }
   ],
   "source": [
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print(f'{n}: {\", \".join(topic_words)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "topic_model_2 = ct.Corex(n_hidden= 5,\n",
    "                       words=words,\n",
    "                       seed=1\n",
    "                       )\n",
    "\n",
    "topic_model_2.fit(doc_word,\n",
    "                words= words,\n",
    "                docs= df.responsibilities,\n",
    "                anchors=[\n",
    "                    ['business', 'analysis', 'stakeholders', 'communication'],\n",
    "                    ['production', 'build', 'deploy', 'develop', 'code'],\n",
    "                    ['models', 'develop', 'tune', 'data'],\n",
    "                    ['balance', 'culture'],\n",
    "                    ['startup', 'disruption', 'mission', 'join']\n",
    "                ],\n",
    "                anchor_strength=5\n",
    "                );"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: business, analysis, stakeholders, communication, analytics, insights, analytical, advanced, statistical, results\n",
      "1: production, code, deploy, build, develop, learning, software, machine, engineers, ml\n",
      "2: models, data, develop, predictive, model, algorithms, tune, optimize, monitor, predict\n",
      "3: culture, balance, diversity, people, inclusive, committed, employees, inclusion, life, work\n",
      "4: mission, join, scientist, startup, team, role, disruption, experience, working, looking\n"
     ]
    }
   ],
   "source": [
    "topics_2 = topic_model_2.get_topics()\n",
    "for n,topic in enumerate(topics_2):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print(f'{n}: {\", \".join(topic_words)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "[(\"|Systems Planning and Analysis, Inc. (SPA) is a well-established and progressive defense contracting company in the Northern Virginia area just a few miles south of the Pentagon. We are a professional services firm established in 1972 that has a long-standing reputation for unrivaled technical and analytical support to some of the top decision makers in the Federal Sector. We do state of the art work and have a cadre of outstanding professionals on our team.|Veracity Forecasting Group is part of the Maritime Division within SPA. Our unique processes result in authoritative, data-driven analyses that assist enterprise managers in making complicated decisions. We offer our customers proven expertise in descriptive, predictive, and prescriptive analytics; advanced mathematics and computational techniques (a.k.a. data science); and software engineering. Our mission is to help enterprise leaders make complex, fully informed decisions and save money in the process.|SPA has an immediate need for a mid-level Defense Data Scientist.|#CJ #IN123|Responsibilities|Everybody’s view of data science is a little different, and we are no exception. In SPA's Veracity Forecasting Group, we view data science as a way of understanding “how the world works.” We make assumptions and models then use data of all sorts to validate or disprove them. Our customers ask tough questions about managing their multifaceted enterprises; we build and operate complex models and simulations to provide the answers that best address the decisions they face.|We don’t expect you to come in with all of the subject matter expertise needed to completely understand the data analysis or to create models with the fidelity we require. We do expect you to get there quickly, though. We look for traits such as how you solve problems when you’re stuck. Do you look for creative ways to apply different techniques from tangential disciplines? Do you crack open a book and teach yourself how to do something new? Do you collaborate with your colleagues? If you take initiatives like these, you would fit in well with our team of analysts.|We would love to tell you that we spend all our time developing elaborate algorithms for regression, survival, kernel weighting, etc., but honestly, we spend a lot of time wrangling data. This includes combing data from disparate data systems, manipulating formats, and cleaning—all of which are required to make the modeling happen. For this critical work we need someone who is precise, efficient, and tenacious.|\",\n  0.0),\n (\" Be Doing...|As a Senior/Distinguished Data Scientist you will work closely with data science and engineering teams and the entire data scientist community at Verizon in proactively designing and developing AI capabilities. These AI capabilities will include predictive, prescriptive and adaptive applications for all predictions and inferences at Verizon. Models will typically get implemented on premise, in cloud and/or on the edge and in both real-time and batch mode depending upon the business applications.|This is a technical lead role with strong expertise in machine learning and experience with implementation of AI in commercial applications. You will be recognized as an expert in machine learning and data science.|At Verizon, we are on a multi-year journey to industrialize our data science and AI capabilities. Very simply, this means that AI will fuel all decisions and business processes across the company. At $130B+ in annual revenue, this is a pioneering opportunity to design and shape AI at scale in the Telco industry. With our leadership in bringing 5G network nationwide, the opportunity for AI will only grow exponentially in going from enabling billions of predictions to possibly trillions of predictions that are automated and real-time. Therefore, it will be critical that this candidate possess previous experience in research and validation of AI and data science techniques.|Partner with key business stakeholders to develop AI strategy and roadmap and develop and execute plans to deliver business results.|Independently manage portfolios of AI projects and design, develop, and deliver AI solutions from E2E.|Develop the next generation of AI that drives innovation and business growth, improves customer experience and increases operational efficiency.|Operate as an expert both within Verizon and externally within industry.|Serve as a technical thought leader and advisor to the organization and trusted advisor to our business partners.|Stay informed on the latest advancements in AI and technology space, finding ways to deliver value by applying and customizing these to our specific problem space.|Drive innovation by introducing state of the art AI techniques and technology to the team.|Actively research and develop new techniques/solutions to solve business problems and accelerate AI Industrialization.|Help create an environment where our scientists are engaged in pioneering work that can be shared with the world in a number of ways (e.g., open source, publications).|Help establish best practices and governance routines to ensure adherence to model management policies, peer reviews, and compliance to our policy standards for privacy, ethics, and bias.|Mentor and coach junior data scientists in their career development and technical knowledge and skills.|Help attract, recruit, and retain top data science and AI talent and build a diverse team with an inclusive culture.|Where You’ll Work|In this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager.|What We’re \",\n  0.0),\n (\"|As a software development/machine learning engineer on the Amazon SageMaker Studio IDE team, you’ll own the Notebook authoring and data scientist IDE experience for AWS ML. You will build/support state-of-the art IDEs on Studio, both web-based and local. Users can choose their preferred IDE on Studio, which will serve as the single place of development environment where users can create experiments, build and evaluate models, debug performance issues, compare experiments, and deploy models. Your team's mission is to provide a highly scalable and collaborative data science workbench where any data scientist, developer, or student can launch a wholly configured and collaborative workspace in the cloud.|A day in the life|You will be responsible for translating business and functional requirements into concrete deliverables with the design, development, testing, and deployment of highly scalable distributed services. You will also partner with other ML teams to help invent, implement, and connect sophisticated algorithms to our cloud based engines. Prior domain knowledge including AI and ML is preferred, though not required.|However, strong motivation to learn ML and AI is critical for successful candidates.|Candidates should also be very agile in developing flexible software with respect to scientific, experimentation methods and usage patterns.|Additional Responsibilities Include|Designing, developing and maintaining core system features, services and engines|Helping define product features, drive the system architecture, and spearhead the best practices that enable a quality product|Working with external customers, scientists and other engineers to investigate design approaches, prototype new technology, and evaluate technical feasibility|Operating in an Agile/Scrum environment to deliver high quality software against aggressive schedules|About The Team|Amazon SageMaker is the world’s first fully integrated development environment tailored for machine learning, and is growing rapidly to be the tool of choice for machine learning scientists and practitioners all around the world. SageMaker Studio is our flagship ML IDE for ML development activities including notebooks, experiment management, automatic model creation, debugging, and model and data drift detection. We are looking for talented engineers to build the next generation IDE. We show pride in an inclusive environment that celebrates knowledge sharing, mentorship, and career growth.|About Us|Inclusive Team Culture|Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.|Work/Life Balance|Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.|Mentorship & Career Growth|Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.|Basic \",\n  0.0)]"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_2.get_top_docs(topic=3, n_docs=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "        topic0    topic1    topic2    topic3    topic4\n2276  0.999997  0.999999  0.999968  0.000001  0.000001\n2019  0.000001  0.999999  0.999999  0.000001  0.000001\n1717  0.999999  0.000001  0.999999  0.000001  0.000001\n527   0.000001  0.000001  0.000001  0.000001  0.000001\n3728  0.999999  0.000001  0.999999  0.000001  0.000001\n809   0.000001  0.999999  0.999998  0.000001  0.000001\n1045  0.154966  0.999999  0.999997  0.000001  0.999999\n816   0.000016  0.000083  0.999999  0.000001  0.000001\n2555  0.999999  0.000001  0.000001  0.000001  0.999999\n1312  0.000001  0.000054  0.999999  0.000001  0.000001\n1105  0.000001  0.000001  0.999994  0.000001  0.000001\n1324  0.000001  0.999999  0.000001  0.000001  0.000001\n188   0.999996  0.999999  0.000001  0.000001  0.000001\n29    0.000001  0.000001  0.000001  0.000001  0.000001\n1450  0.999999  0.999999  0.000001  0.999999  0.999999\n2351  0.999999  0.999999  0.999999  0.999999  0.999999\n1231  0.999999  0.999999  0.999992  0.000001  0.000001\n2936  0.000001  0.000001  0.000001  0.000001  0.000001\n3201  0.000001  0.000006  0.999997  0.000001  0.000001\n1251  0.999999  0.000017  0.999999  0.000001  0.000001\n1505  0.000382  0.999999  0.999999  0.000001  0.000001\n3540  0.000001  0.000001  0.000001  0.000001  0.000001\n3322  0.000001  0.000011  0.000001  0.000001  0.000001\n2557  0.000002  0.000001  0.000001  0.000001  0.000001\n265   0.999999  0.999999  0.999997  0.000001  0.000001\n3734  0.999999  0.999999  0.999999  0.000001  0.000057\n1580  0.004354  0.000216  0.999999  0.000001  0.000001\n934   0.000001  0.999999  0.999994  0.000001  0.000001\n1882  0.999999  0.999999  0.000001  0.000001  0.999999\n1804  0.000001  0.000001  0.000003  0.000001  0.000001\n2090  0.999999  0.999999  0.000001  0.000001  0.000001\n3580  0.000001  0.999999  0.000001  0.000001  0.000001\n1452  0.000001  0.000001  0.000001  0.000001  0.000001\n2269  0.999999  0.000041  0.999997  0.999999  0.999999\n3738  0.999999  0.000526  0.999999  0.000001  0.000001\n509   0.000001  0.000001  0.000001  0.999999  0.000001\n3384  0.999999  0.999999  0.999999  0.999999  0.999999\n72    0.000001  0.004767  0.000001  0.999999  0.999999\n1821  0.000317  0.002965  0.000001  0.000001  0.000001\n3338  0.000001  0.999999  0.999989  0.000012  0.000148\n1431  0.000001  0.000003  0.999999  0.000001  0.000001\n1831  0.000001  0.999999  0.000001  0.000001  0.000001\n2460  0.000001  0.000001  0.000001  0.000001  0.000001\n648   0.000005  0.000121  0.000001  0.999999  0.999999\n1012  0.999999  0.000001  0.999999  0.000001  0.000001\n3019  0.999999  0.000001  0.000001  0.000001  0.000001\n1488  0.000217  0.999999  0.000001  0.000001  0.000001\n2775  0.999999  0.998356  0.999999  0.000001  0.000001\n407   0.000001  0.000001  0.000001  0.999999  0.000168\n2425  0.000001  0.000048  0.999991  0.999999  0.999992",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic0</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>topic3</th>\n      <th>topic4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2276</th>\n      <td>0.999997</td>\n      <td>0.999999</td>\n      <td>0.999968</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>2019</th>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>1717</th>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>527</th>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>3728</th>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>809</th>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.999998</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>1045</th>\n      <td>0.154966</td>\n      <td>0.999999</td>\n      <td>0.999997</td>\n      <td>0.000001</td>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>816</th>\n      <td>0.000016</td>\n      <td>0.000083</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>2555</th>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>1312</th>\n      <td>0.000001</td>\n      <td>0.000054</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>1105</th>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.999994</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>1324</th>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>0.999996</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>1450</th>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>2351</th>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>1231</th>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.999992</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>2936</th>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>3201</th>\n      <td>0.000001</td>\n      <td>0.000006</td>\n      <td>0.999997</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>1251</th>\n      <td>0.999999</td>\n      <td>0.000017</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>1505</th>\n      <td>0.000382</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>3540</th>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>3322</th>\n      <td>0.000001</td>\n      <td>0.000011</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>2557</th>\n      <td>0.000002</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>265</th>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.999997</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>3734</th>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000057</td>\n    </tr>\n    <tr>\n      <th>1580</th>\n      <td>0.004354</td>\n      <td>0.000216</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>934</th>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.999994</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>1882</th>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>1804</th>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000003</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>2090</th>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>3580</th>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>1452</th>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>2269</th>\n      <td>0.999999</td>\n      <td>0.000041</td>\n      <td>0.999997</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>3738</th>\n      <td>0.999999</td>\n      <td>0.000526</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>3384</th>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>0.000001</td>\n      <td>0.004767</td>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>1821</th>\n      <td>0.000317</td>\n      <td>0.002965</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>3338</th>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.999989</td>\n      <td>0.000012</td>\n      <td>0.000148</td>\n    </tr>\n    <tr>\n      <th>1431</th>\n      <td>0.000001</td>\n      <td>0.000003</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>1831</th>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>2460</th>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>648</th>\n      <td>0.000005</td>\n      <td>0.000121</td>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>1012</th>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>3019</th>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>1488</th>\n      <td>0.000217</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>2775</th>\n      <td>0.999999</td>\n      <td>0.998356</td>\n      <td>0.999999</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>407</th>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.999999</td>\n      <td>0.000168</td>\n    </tr>\n    <tr>\n      <th>2425</th>\n      <td>0.000001</td>\n      <td>0.000048</td>\n      <td>0.999991</td>\n      <td>0.999999</td>\n      <td>0.999992</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_colms = ['topic'+str(i) for i in range(topic_model_2.labels.shape[1])]\n",
    "\n",
    "predictions = pd.DataFrame(topic_model_2.p_y_given_x, columns=topic_colms)\n",
    "predictions.sample(50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "(3850, 5)"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent for topic0: 43.1\n",
      "Percent for topic1: 40.9\n",
      "Percent for topic2: 53.1\n",
      "Percent for topic3: 18.8\n",
      "Percent for topic4: 27.4\n"
     ]
    }
   ],
   "source": [
    "for number in range (0, 5):\n",
    "    name = f\"topic{str(number)}\"\n",
    "    percentage = predictions[name].sum()/len(predictions) * 100\n",
    "\n",
    "    print(f\"Percent for {name}: {percentage:.1f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "[(':|Artificial Intelligence (AI) and Machine Learning (ML) algorithms can significantly speed up drug discovery and shorten drug development and identification of patients for clinical trials thereby creating better medicines that save lives. AI and Deep Analytics (AIDA) is a critical group in Digital and Data Science (DDS) organization at Sanofi R&D focused on applications of AI/ML and Deep Learning (DL) in drug design, multi-omics diseases modeling, drug development, and analysis of outcomes of clinical trials.|Our existing research and development areas include Omics Data Science applied to single-cell RNA sequences, multi-omics data integration, and real word data (RWD); Biologics Drug Design; Natural Language Processing (NLP); Deep Learning-based Imaging and bioimaging for digital pathology and Spatial Biology; digital signal processing (DSP) and machine learning applied to digital health and patient-generated data from wearables.|Scientists in our team come from diverse backgrounds in computational sciences and engineering with deep expertise in AI/ML, deep learning, biostatistics and algorithms.|We are seeking a Senior Data Scientist to join the AI and Deep Analytics (AIDA), Omics Data Science (ODS) team. ODS closely interacts with Precision Oncology, Precision Immunology and Translational Sciences at Sanofi R&D.|The successful candidate will have extensive experience in advanced statistics, machine learning and knowledge graph development with published studies aimed at identifying causality in complex real-world datasets. The candidate should also have excellent oral and written communication skills, the ability to learn and acquire new techniques and methodologies as well as a strong tropism for teamwork.|The candidate is expected to lead and execute analytical strategies for patient deep phenotyping using molecular, real-world and clinical data for new indication identification, disease endotype characterization and drug repurposing.|The candidate will directly report to the Global Head of AI and Deep Analytics at Sanofi R&D.|The responsibilities of the senior data scientist in AI and Deep Analytics will include:|Applying AI/ML for modeling and embedding of data plus performing tasks such as classification, clustering, prediction, generation, relationship discovery, and causal inference.|Building models from knowledge graphs obtained from internal and external data sources.|Close interactions with other data scientists as well as scientists in immunology, oncology, and translational sciences, in an insertional context (US, Europe, China)|Update and report relevant results to interdisciplinary project teams and stakeholders|Maintain a keen awareness of recent developments in data science and bioinformatics and state-of-the-art of AI/ML/DL algorithms and research results|Active engagement in evaluation and coordination of both academic and startup collaborations|',\n  0.0),\n ('|At Perficient you’ll deliver mission-critical technology and business solutions to Fortune 500 companies and some of the most recognized brands on the planet. And you’ll do it with cutting-edge technologies, thanks to our close partnerships with the world’s biggest vendors. Our network of offices across North America, as well as locations in India and China, will give you the opportunity to spread your wings, too.|We’re proud to be publicly recognized as a “Top Workplace” year after year. This is due, in no small part, to our entrepreneurial attitude and collaborative spirit that sets us apart and keeps our colleagues impassioned, driven, and fulfilled.|Perficient currently has a career opportunity for a|Data Scientist|.|Job Overview|The role of the Data Scientist is for individuals passionate about identifying and delivering the right Business solution for each client using AI/ML. Our Data Scientists are keen to understand our customer needs, processes and pain points to determine the success factors and evaluation criteria that will needed to measure the effectiveness of an ML model.|The Data Scientist will be involved in the strategic planning of an engagement or helping the client make decisions about their future AI/ML roadmap and vision. Once the project as begun, the Data Scientist will be responsible for the execution of our established methodology, work with customer and/or the teams data engineer to identify data ingestion and transformation needs, exploration of the data and reporting findings, modeling and evaluation of training iterations. It is a key part of the role to be able to explain in non-technical terms the chosen modeling approach and findings from data exploration or training results.|The Data Scientist will work with Senior Project Managers to assist with daily operations exercising time management, communication and collaboration in a fast-paced environment to ensure the successful delivery of projects. The Data Scientist will interface with Perficient technical and business delivery personnel, as well as vendors and customers on a regular basis. May mentor junior data scientists.|Responsibilities|Use your machine learning (ML) expertise to research and recommend the best approaches to provide technology and business solutions by utilizing statistical/ mathematical methods (classification, time-series analysis, regression, statistical inference, …) or deep learning techniques.|Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data, and identify patterns.|Work directly with clients and stakeholders to present and explain the key techniques and major results generated using non-technical language; understand client feedback and be able to accommodate back into the model through programming or additional feature engineering.|Come up with innovative, repeatable, business use cases for real world recommendation techniques, and quickly develop prototypes to test these use cases.|Utilize a diverse array of technologies, tools and clous services as needed, to deliver insights, such as Microsoft Azure.|Translate customer pain points, needs and requirements into creative ML solutions.|Help define automated AI/ML pipeline for both training and runtime predictions.|Assist in the development of guidelines, best practices and knowledge sharing documentation|Ability to deliver on schedule and communicate effectively to ensure alignment between operations and technology .|Ability to educate customer on project goals and solution and set realistic expectations.|',\n  0.0),\n (\"We are looking for a talented Lead Data Scientist to join us in the continued success of our rapid growth trajectory. You will be our in-house decision science/data science expert, would manage two Senior Data Scientists and be expected to work closely with the CRO, global management team, and other colleagues across the business to assist in the management of a £400m revolving credit portfolio. In addition to building and maintaining statistical models in the UK and US you would also get involved with a broad range of analytics activities including lifetime value modelling, pricing, limit setting, provisioning and product optimisation. You will directly impact the bottom line of the business through direct implementation of your ideas, theories, and models from start to finish. You will help enable the business to achieve its core mission of supporting small businesses growth across the UK and US through a high quality and effective product offering. .|What You'll Be Doing|You will help us achieve our overall business goals; this means that in addition to your deep technical skills you also have an interest in, and the ability to help drive, the commercial side of our business,|You will help manage, coach and develop colleagues in marketing, decisioning, collections, business intelligence and compliance on data science tools and techniques, as well as taking a direct lead on the priority projects in these areas.|You will build, implement and monitor a wide range of statistical predictive models across the UK and US, influencing our strategy across the entire customer lifecycle from marketing through to collections,|You will develop the data pipelines and create the infrastructure necessary to facilitate a high performing, efficient data science team,|You will use your advanced analytical skill to help drive Credit decision making and overall Risk strategy including on topics such as setting and monitoring risk appetite, lifetime value modelling, pricing, and credit limit strategy,|You can work collaboratively with business stakeholders (from C-level execs to front line staff) to ensure risk analysis can be implemented seamlessly without deterioration to customer experience or complex IT builds|You will constantly be refining our decisioning process to improve its efficiency through greater use of automation|Our data environment|Our analytical data environment is hosted in Snowflake (SQL based) with use of DBT and FiveTran to manage our data pipelines|Day to day modelling building takes place in Python / JupyterLab|We use a Kubernetes cluster, hosted in Azure, for heavy analytical tasks and model builds|Our business analyst pool makes heavy use of Looker for data visualization|What We Are \",\n  0.0),\n (' Do|Find opportunities and solutions across all dimensions of the business in which data science and sophisticated analytics can provide meaningful insights, drive operational improvements, and “move the needle” for our key business outcomes|Partner with product, program, marketing, sales, and support teams to understand their strategic objectives and tactics, and to develop roadmaps for data-driven optimization using the principles of machine learning and statistical analysis.|Be one of Zwift’s experts on quantitative analysis and machine learning methodologies, coaching colleagues and stakeholders to improve company-wide understanding of the role and application of predictive analytics, and continually advancing internal modeling, experimentation, and other analytical capabilities|Help drive continuous improvements in our core machine learning, forecasting, data, model deployment and reporting capabilities.|Actively “push the boundary” of our technical capabilities and help drive ideation for our analytics R&D efforts.|Foster the role of data science and be a trusted, objective, and recognized “voice of the data” across the organization|Actively mentor junior colleagues on the Data Science and Data & Insights teams, providing meaningful development and learning opportunities.|Collaborate with product and engineering teams to ensure that the product roadmap is aligned rigorously supported by data science|Support ad hoc request from the business that require advanced analytical and modeling capabilities|Be a senior representative of the Data & Insights Team and proactively communicate key insights and analysis to stakeholders at all levels of the company|What We’re ',\n  0.0)]"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_2.get_top_docs(topic=0, n_docs=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "doc_topic_corex = topic_model_2.p_y_given_x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_topic_corex)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "3850"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_topic_corex)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('doc_topic_corex.pickle', 'wb') as handle:\n",
    "    pickle.dump(doc_topic_corex, handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}