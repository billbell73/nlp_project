{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "12777"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('jobs_linkedin_loads.pickle', 'rb') as handle:\n",
    "    jobs = pickle.load(handle)\n",
    "\n",
    "len(jobs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': '2912844894',\n 'description': '<div class=\"description__text description__text--rich\">\\n<section class=\"show-more-less-html\" data-max-lines=\"5\">\\n<div class=\"show-more-less-html__markup show-more-less-html__markup--clamp-after-5\">\\n        Project Canary is a growth-stage, SaaS and certification company combatting climate-change from an incredible vantage point that can impact oil &amp; gas, utilities, landfills, and ag. We are a Public Benefit Corp (B-Corp rating score 107) that helps monitor and mitigate emissions in the ESG landscape favored by communities and investors alike through independent data tied to carbon and environmental footprints. With flexible work environments in Denver,<br/><br/>Project Canary’s mission is to make net-zero a reality by quantifying climate change and putting actionable insights into the hands of the energy sector. Our diverse and inclusive team of operators, scientists, engineers, and sales leaders know how to network, hustle, and are change-makers by design. We ingest data from various sources, including our own proprietary environmental sensors/hardware, to calculate carbon emissions from different facilities in real-time displayed on a SaaS dashboard. The resulting independent, trusted data can inform the procurement of offsets in real-time using microtransactions, formulate a data-driven ESG strategy that investors now demand, improve operations by identifying problem areas in minutes, and bolster customer engagement through radical supply chain transparency.<br/><br/>Initially, we are focused on the energy industry. With thousands of energy assets analyzed and hundreds of environmental and air quality sensors currently deployed, Project Canary is positioned better than anyone to provide empirical ESG data—and we have the ARR and growing pains to prove it.<br/><br/>Project Canary’s success is attributed to the motivation, skill, and teamwork of everyone. The team understands the importance of maintaining a culture where relationships are valued, feedback is crucial, and trust in each other and our products/services is paramount. If you enjoy a growth-stage environment, mission-driven work, we want to hear from you.<br/><br/>As a scaling PBC, we have excellent healthcare, a people-first orientation, and a sustainability core.<br/><br/>The Data Scientist will be part of the Data and Analytics team responsible for research and development of advanced predictive modeling to diverse problems across the oil and gas, utilities, and waste management value chain.<br/><br/>You are a team player who has a significant academic and industrial experience applying first principle-based models such as CFD and reduced order models and state of the art machine learning (Regression, Classification, Decision Trees, Random Forests) and deep learning techniques (CNN, RNN, LSTM, GRU).<br/><br/><strong>Job Responsibilities:<br/></strong><ul><li>Support Data and Analytics team through development of plume dispersion modeling to resolve complex fluid problems in an open field</li><li>Execute the certification through the review of a company\\'s documentation, personnel interviews, and evaluation of well pad design</li><li>Assist the development of white papers for quantification analysis as well as additional technical and professional writing </li><li>Engagement with various disciplines within the Project Canary team including science, software, and regulatory members </li><li>Develop and support scientific projects that enhance our understanding of methane emission patterns and opportunities for enhanced methane mitigation from production and distribution of oil and gas globally </li><li>Play a role in designing, planning and execution of PC expanding work on quantifying methane emissions using first principal engineering methods, mathematical models, and statistical analysis</li><li>Coordinate and ensure rigor of scientific initiatives collaboratively undertaken with a diverse group of stakeholders including industry, academics, multilateral organizations, and the public sector</li><li>Remain at the forefront of climate science, including staying up to date with scientific literature <br/><br/></li></ul><strong>Requirements<br/><br/></strong><strong>Education and experience:<br/></strong><ul><li>3+ years\\' experience quantifying emissions data</li><li>Strong background in fluid flow, CFD, Data Analytics </li><li>Competent in programming languages such as Python, C#, and Matlab </li><li>At least a bachelor\\'s degree in Mechanical Engineering or relevant engineering field </li><li>Advanced degree and/or professional certifications helpful </li><li>Experience in performing rigorous analysis with short deadlines in support of highly visible work</li><li>Demonstrated scientific expertise, including but not limited to a record of scholarly publications and/or involvement in scientific panels</li><li>Experience synthesizing, interpreting, and communicating scientific data in an advocacy setting and for non-scientific populations </li><li>Vaccination required <br/><br/></li></ul><strong>Benefits<br/></strong><ul><li>Full coverage of health, dental, and vision insurance</li><li>401K company match</li><li>Student loan assistance</li><li>Salary range: $90,000- $120,000 annual base</li><li>Stock options</li><li>World recognized work culture - ranked top 5% of all B-Corps <br/><br/></li></ul><em>Project Canary provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.<br/><br/></em><em>This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.</em>\\n</div>\\n<button aria-expanded=\"false\" aria-label=\"Show more, visually expands previously read content above this button\" class=\"show-more-less-html__button show-more-less-html__button--more\" data-tracking-control-name=\"public_jobs_show-more-html-btn\">\\n        Show more\\n\\n        <icon class=\"show-more-less-html__button-icon\" data-delayed-url=\"https://static-exp1.licdn.com/sc/h/cyolgscd0imw2ldqppkrb84vo\"></icon>\\n</button>\\n<button aria-expanded=\"true\" aria-label=\"Show less\" class=\"show-more-less-html__button show-more-less-html__button--less\" data-tracking-control-name=\"public_jobs_show-less-html-btn\">\\n        Show less\\n\\n        <icon class=\"show-more-less-html__button-icon\" data-delayed-url=\"https://static-exp1.licdn.com/sc/h/4chtt12k98xwnba1nimld2oyg\"></icon>\\n</button>\\n</section>\\n</div>',\n 'title': 'Data Scientist',\n 'companyInfo': 'Project Canary|Denver, CO',\n 'responsibilities': \":|Support Data and Analytics team through development of plume dispersion modeling to resolve complex fluid problems in an open field|Execute the certification through the review of a company's documentation, personnel interviews, and evaluation of well pad design|Assist the development of white papers for quantification analysis as well as additional technical and professional writing|Engagement with various disciplines within the Project Canary team including science, software, and regulatory members|Develop and support scientific projects that enhance our understanding of methane emission patterns and opportunities for enhanced methane mitigation from production and distribution of oil and gas globally|Play a role in designing, planning and execution of PC expanding work on quantifying methane emissions using first principal engineering methods, mathematical models, and statistical analysis|Coordinate and ensure rigor of scientific initiatives collaboratively undertaken with a diverse group of stakeholders including industry, academics, multilateral organizations, and the public sector|Remain at the forefront of climate science, including staying up to date with scientific literature|\"}"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['2912844894']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "data": {
      "text/plain": "{2: 12762, 3: 12, 4: 2, 1: 1}"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for key, value in jobs.items():\n",
    "    info = value['companyInfo'].split('|')\n",
    "    elements_count = len(info)\n",
    "\n",
    "    if not elements_count in results:\n",
    "        results[elements_count] = 1\n",
    "    else:\n",
    "        results[elements_count] += 1\n",
    "\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "def experience_level(job):\n",
    "    title = str.lower(job['title'])\n",
    "    if any(substring in title for substring in [\"senior\", \"lead\", \"principal\"]):\n",
    "        return \"senior\"\n",
    "    if any(substring in title for substring in [\"junior\", \"intern\", \"grad\"]):\n",
    "        return \"junior\"\n",
    "\n",
    "    description = str.lower(job['description'])\n",
    "    if bool(re.search('([5678]\\+ years|[5678] years)', description)):\n",
    "        return \"senior\"\n",
    "\n",
    "    return \"mid\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "data": {
      "text/plain": "'senior'"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience_level({\"title\": \"Senior Data Scientist\"})\n",
    "experience_level({\"title\": \"Data Scientist - Intern\"})\n",
    "experience_level({\"title\": \"Data Scientist\", \"description\": \"blah blah 7 years experience\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "def is_relevant(job):\n",
    "    title_pattern = \"(?:data scientist|data science|machine learning)\"\n",
    "    return bool(re.search(title_pattern, job['title'], re.IGNORECASE))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_relevant({\"title\": \"Senior Data Scientist\"})\n",
    "is_relevant({\"title\": \"Software - Intern\"})\n",
    "is_relevant({\"title\": \"Engineer Machine Learning\", \"description\": \"blah blah 7 years experience\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "pattern_start = \"[Rr]esponsibilities|[Ww]hat [Yy]ou['’]ll|[Ww]hat [Yy]ou [Ww]ill|[Dd]uties|[Tt]he [Rr]ole.{0,10}\\||[Oo]verview|[Ww]ork.{0,10}\\|\"\n",
    "\n",
    "pattern_end = \"Requirements|[Qq]ualifications|Skills.{0,10}\\||[Ll]ooking [Ff]or.{0,5}\\||[Yy]ou [Hh]ave:\"\n",
    "\n",
    "pattern = f\"(?:{pattern_start})(.*?)(?:{pattern_end})\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "job_responsibilities = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for key, value in jobs.items():\n",
    "    description = (value['description'])\n",
    "    soup = bs(description)\n",
    "\n",
    "    text = soup.get_text(\"|\", strip=True)\n",
    "    match = re.findall(pattern, text)\n",
    "\n",
    "    soup.button.decompose()\n",
    "    soup.button.decompose()\n",
    "\n",
    "    if is_relevant(value) and match and len(match[0]) > 130:\n",
    "        company_info = value['companyInfo'].split('|')\n",
    "        company_name = company_info[0] if len(company_info) > 0 else \"\"\n",
    "        location = company_info[1] if len(company_info) > 1 else \"\"\n",
    "\n",
    "        job_responsibilities[key] = {\n",
    "            'responsibilities' : match[0],\n",
    "            'title' : value['title'],\n",
    "            'description': str(soup),\n",
    "            'companyName': company_name,\n",
    "            'location': location,\n",
    "            'level': experience_level(value)\n",
    "        }\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "    # if (counter > 5):\n",
    "    #     break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "[('2908496770',\n  {'responsibilities': ':|•\\tDesign and implement ML methods on proprietary and open-access datasets;|•\\tUtilize large-scale datasets to generate statistically motivated research hypotheses;|•\\tApply statistical methods to rigorously test and evaluate research hypotheses;|•\\tDevelop and foster external collaborations;|•\\tProvide expert technical guidance and support customers in the design and analysis of experiments;|•\\tWork both independently and as part of a collaborative team to develop data analysis and machine learning solutions.|',\n   'title': 'Data Scientist',\n   'description': '<html><body><div class=\"description__text description__text--rich\">\\n<section class=\"show-more-less-html\" data-max-lines=\"5\">\\n<div class=\"show-more-less-html__markup show-more-less-html__markup--clamp-after-5\">\\n        I am looking for a self-motivated data scientist with machine learning experience. You will be working on a ground-breaking cloud R&amp;D platform designed to integrate the volumes of scientific resources, helping to build a digital workplace with direct impact on human health, pharmaceutical research and Life Sciences companies. This opportunity requires a strong technical background in machine learning; utilizing methods for understanding large scale biological data. <br/><br/>Responsibilities:<br/>•\\tDesign and implement ML methods on proprietary and open-access datasets;<br/>•\\tUtilize large-scale datasets to generate statistically motivated research hypotheses;<br/>•\\tApply statistical methods to rigorously test and evaluate research hypotheses;<br/>•\\tDevelop and foster external collaborations;<br/>•\\tProvide expert technical guidance and support customers in the design and analysis of experiments;<br/>•\\tWork both independently and as part of a collaborative team to develop data analysis and machine learning solutions.<br/>Requirements:<br/>•\\tPh.D. degree with 3+ years (or MS degree with 5+ years) of working experience in the industry in the field of systems biology, bioinformatics, computational biology, data science, ML, or equivalent;<br/>•\\tExtensive experience applying ML techniques to large scale genomics and/or high throughput biological data sets;<br/>•\\tStrong technical knowledge of molecular biology, genetics, and bioinformatics;<br/>•\\tProficient in either R or Python;<br/>•\\tExperience with ML frameworks such as Torch, PyTorch, TensorFlow, Scikit-learn, etc.;<br/>•\\tFamiliarity with Atlassian JIRA;<br/><br/>This is a fully remote position with a package of up to $200K plus benefits<br/>\\n</div>\\n\\n\\n</section>\\n</div></body></html>',\n   'companyName': 'Data Revolution',\n   'location': 'San Francisco Bay Area',\n   'level': 'senior'}),\n ('2911267267',\n  {'responsibilities': \":|• Provide consultative support as and when required and should be able|to handle complex|projects independently|• Perform exploratory data analysis, data deep dives and generate data|insights|• Substantial portion of work would require advanced Data Modelling and|Data Wrangling|• Responsible for implementing multiple model types/methodologies, will|design, test and|architect variety of models based on business requirements|• Build relationships with clients to better understand their business,|and to enable them to|better understand how to use analytics to drive their business|• Develop code, statistical models, dashboards and presentations as per|client requirements|• Present the results of the work to client stake holders and give|insights and|recommendations that have tangible business impacts|• Work with onsite and offshore team to structure solutions based on|analytics tools and|techniques|• Compliance of structured problem-solving approach and documentation of|the same|• Assist the team in process improvement / automation to increase|efficiency|• Build and maintain strong relationships with external and internal|stakeholders|Knowledge:|Qualification:|− BE / B. Tech/Master's in Computer science/Business Analytics/|Statistics|Experience:|− 3-5 years of relevant experience in analytics consulting and|professional services|− At least 1-3 years hands on experience in creating visualizations and|dashboards through insights|− Hands-on experience working with large, complex, and diverse|datasets|− Consultative approach and ability to apply first principles and|structured approaches to problem solving as opposed to relying|excessively on past domain expertise alone|− Ecommerce and Retail experience strongly preferred|\",\n   'title': 'Data Scientist',\n   'description': '<html><body><div class=\"description__text description__text--rich\">\\n<section class=\"show-more-less-html\" data-max-lines=\"5\">\\n<div class=\"show-more-less-html__markup show-more-less-html__markup--clamp-after-5\">\\n        Role: Senior Analyst<br/>Key Responsibilities:<br/>• Provide consultative support as and when required and should be able<br/>to handle complex<br/>projects independently<br/>• Perform exploratory data analysis, data deep dives and generate data<br/>insights<br/>• Substantial portion of work would require advanced Data Modelling and<br/>Data Wrangling<br/>• Responsible for implementing multiple model types/methodologies, will<br/>design, test and<br/>architect variety of models based on business requirements<br/>• Build relationships with clients to better understand their business,<br/>and to enable them to<br/>better understand how to use analytics to drive their business<br/>• Develop code, statistical models, dashboards and presentations as per<br/>client requirements<br/>• Present the results of the work to client stake holders and give<br/>insights and<br/>recommendations that have tangible business impacts<br/>• Work with onsite and offshore team to structure solutions based on<br/>analytics tools and<br/>techniques<br/>• Compliance of structured problem-solving approach and documentation of<br/>the same<br/>• Assist the team in process improvement / automation to increase<br/>efficiency<br/>• Build and maintain strong relationships with external and internal<br/>stakeholders<br/><br/>Knowledge:<br/>Qualification:<br/>− BE / B. Tech/Master\\'s in Computer science/Business Analytics/<br/>Statistics<br/><br/>Experience:<br/>− 3-5 years of relevant experience in analytics consulting and<br/>professional services<br/>− At least 1-3 years hands on experience in creating visualizations and<br/>dashboards through insights<br/>− Hands-on experience working with large, complex, and diverse<br/>datasets<br/>− Consultative approach and ability to apply first principles and<br/>structured approaches to problem solving as opposed to relying<br/>excessively on past domain expertise alone<br/>− Ecommerce and Retail experience strongly preferred<br/><br/>Skills:<br/>Technical/Domain:<br/>− 1-3 years of experience working with Tableau and analysing large<br/>datasets<br/>− Strong SQL query skills and experience in BI Dashboards required<br/>− Experience with Exploratory Data Analysis<br/>− At least 1+ year of experience working with Python / R programming<br/><br/>Competencies:<br/>Behavioural:<br/>− Must have exceptional and effective communication,<br/>organization, and time management skills<br/>− Must be pro-active and determined (Initiates action, Analytical<br/>and problem solver)\\n      </div>\\n\\n\\n</section>\\n</div></body></html>',\n   'companyName': 'TrueSkilla',\n   'location': 'United States',\n   'level': 'senior'})]"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(job_responsibilities.items())[:2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2908496770 (Count: 1. Index: 0)\n",
      ":|•\tDesign and implement ML methods on proprietary and open-access datasets;|•\tUtilize large-scale datasets to generate statistically motivated research hypotheses;|•\tApply statistical methods to rigorously test and evaluate research hypotheses;|•\tDevelop and foster external collaborations;|•\tProvide expert technical guidance and support customers in the design and analysis of experiments;|•\tWork both independently and as part of a collaborative team to develop data analysis and machine learning solutions.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2887210441 (Count: 2. Index: 150)\n",
      ":|Build models to understand and predict metrics like user growth, future revenue, conversion, churn, and more.|Manage recurring revenue (MRR/ARR) calculations, retention analysis and pipelines.|Focus on uncovering critical insights and delivering models to leverage those findings thus powering intelligent business decisions.|Create, manage and improve KPI dashboards for all departments.|Collaborate with leadership, sales, finance, product, engineering, operations and marketing teams to identify, and optimize revenue enhancing opportunities.|Drive measurable business value and communicate the results to technical and non-technical stakeholders.|This person will be managing a Business Analyst as part of their responsibilities.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2899949011 (Count: 3. Index: 300)\n",
      "|:|Help translate business goals and capability needs into analytical model design and machine learning use cases|Provide points of view on feasibility and timing to implement analytics models for product components|Collaborate within a multi-functional and multi-geographical data engineering and data science team developing analytics components of SaaS products|Develop, test and validate multivariate predictive models on actual client data, starting with proofs of concept to verify your hypotheses and iterating in order to identify the optimal predictive models|Test quality of model results of models before embedding within products|Evaluate new data sources for quality of use in analytical models and the product platform (media exposure, demographic and lifestyle attributes, behavioral transactions)|Interpret the models that are being generated, and communicate the design and outcomes to technical and non-technical stakeholders|Participate in the agile software development lifecycle by reporting progress and adding to related tasks and workstreams|Minimum \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2871412778 (Count: 4. Index: 450)\n",
      "|Partners with ASIC team members and key stakeholders at Campus and JPL to find opportunities where data science is part of business solutions, extract and mine data, pinpoint trends, and ensure consistent and accurate results.|Communicates and presents findings to ASIC team members and key stakeholders at Campus and JPL.|Serves as an expert in data science efforts at Campus and JPL including recommending, implementing, and reporting on data science tools, procedures, progress, predictive analytics, and industry innovations.|Discovers and/or designs and builds large and complex data sets including structured and unstructured data.|Performs complex data studies and data discovery around new data sources.|Visualizes and reports data findings creatively and innovatively in a variety of formats.|Provides coaching and mentoring to others within/outside of the ASIC organization on data mining and data science.|Regularly uses creativity and innovation to address important issues.|Exercises discretion and independent judgment in evaluating potential approaches and solutions to significant problems and determining appropriate resolutions.|Frequently interacts with executives, customers, and peers inside and outside the ASIC organization, exchanging and validating comprehensive and analytical information.|Contributes as a key team member on teams inside the ASIC organization. May also team on projects, activities or functions outside the ASIC organization.|Recommends and implements software required for accessing and handling data appropriately.|May design and implement data mining processes and procedures to aid ASIC and customer in continuous monitoring.|Basic \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2710971180 (Count: 5. Index: 600)\n",
      "|Work with large, complex datasets from various sources to draw analytical insights|Research, define, and monitor key indicators to evaluate the autonomous systems performance|Build statistical models from large driving data to predict autonomous driving behavior|Write reusable python/SQL code and share its insights with engineers|Build dashboard to visualize our autonomy performance from both road testing data and simulation test scenarios|Collaborate with other engineers to optimize our autonomy performance evaluation workflow with data-driven approaches|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2905596976 (Count: 6. Index: 750)\n",
      "|Lead the MLOps process, coordinating across data, developer, machine learning, and UX teams; delivering new capabilities and new value across the enterprise|Identify ways to maximize the value of machine learning, while managing risk through ongoing monitoring and computer science development principals|Ensure machine learning solutions meet infrastructure, cybersecurity, privacy, fair banking, and model risk requirements|Drive innovation and continual evolution of the development, deployment, and monitoring of machine learning solutions, especially those that tie into key business applications|Stay current with emerging MLOps trends and tools|Basic \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2875202087 (Count: 7. Index: 900)\n",
      "|H2O.ai is the open source leader in AI with a mission to democratize AI for everyone. H2O.ai is transforming the use of AI with software with its category-creating visionary open source machine learning platform, H2O. More than 18,000 companies use open-source H2O in mission-critical use cases for Finance, Insurance, Healthcare, Retail, Telco, Sales and Marketing. H2O Driverless AI uses \"AI to do AI\" in order to provide an easier, faster and cost-effective means of implementing data science.   H2O.ai partners with leading technology companies such as NVIDIA, IBM, AWS, Intel, Microsoft Azure and Google Cloud Platform and is proud of its growing customer base which includes Capital One, Progressive Insurance, Comcast, Walgreens and MarketAxes. For more information and to learn more about how H2O.ai is driving an AI Transformation, visit www.h2o.ai.|Responsibilities and Duties:|As a Customer Data Scientist, you will collaborate with Data Science teams on the Customer side, work on diverse use cases from several industry verticals, and leverage domain expertise in data science and H2O platform to help customers achieve their AI objectives.|Your primary responsibilities would be to:|Enable customers to solve complex data science problems by providing consultation and guidance on use case identification, feature engineering, model selection and tuning, model deployment and optimization.|Architect, design, and deliver Machine Learning and Data Science solutions.|Demonstrate ML solutions with engaging storytelling and technical accuracy.|Help customers understand model performance, model interpretability, and post deployment model monitoring concepts, and enable them to maximize power of the H2O platform, via training, workshop, and ongoing consultations.|Act as a subject matter expert in H2O platform and data science.|Collaborate with Sales, R&D, and Product teams, to enhance H2O functionality|Translate business cases and requirements into value based technical solutions through the architecture of machine learning workflows and systems from data ingestion to model deployment.|Present at meetups and webinars in the Data Science community, and be an integral part of the Maker culture of creating the best products and solutions.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2882811171 (Count: 8. Index: 1050)\n",
      " Do...|Personalization team at Walmart is dedicated to the mission of knowing our customers better and making it frictionless and faster for them to get what they want while building a trusted partnership with Walmart. We help bring a seamless experience to our customers irrespective of how and where they engage with us – while shopping online or picking groceries at stores. We thrive to provide each customer with a journey tailored to their individual needs, preferences and routines. We operate at the intersection of huge Walmart assortment, millions of customers, thousands of stores and Walmart associates - a multi-layer multi-objective problem space which has a unique impact on Global customer base and powers assisted AI for our associates.|The Personalization team consists of big data geeks, application engineers, scientists and product visionaries all working together to design, prototype and build technology-driven products and experiences that will change the future landscape of e-commerce. We are focused on building an intelligent system that will enable 1:1 personalized customer experience, from finding the product to delivering it to the customer. We are building state-of-the-art probabilistic models and engineering platforms to serve our customer needs by leveraging cutting edge machine learning, deep learning, reinforcement learning, natural language processing, entity-relationship extraction and knowledge representation. This will span many markets, business models and form factors; therefore, we are looking for scientists and engineers who will bring not only an abundance of experiences in technologies, but an abundant curiosity to innovate.|We are looking for versatile Senior Data Scientist to focus on building complex, cutting edge, and scalable algorithms for our organization|Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function.|Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data.|Analytical Modeling: Selects the analytical modeling technique most suitable for the structured, complex data and develops custom analytical models.|Conducts exploratory data analysis activities (for example, basic statistical analysis, hypothesis testing, statistical inferences) on available data.|Defines and finalizes features based on model responses and introduces new or revised features to enhance the analysis and outcomes. Identifies the dimensions of the experiment, finalizes the design, tests hypotheses, and conducts the experiment. Perform trend and cluster analysis on data to answer practical business problems and provide recommendations and key insights to the business. Mentors and guides junior associates on basic modeling and analytics techniques to solve complex problems.|Model Assessment & Validation: Identifies the model evaluation metrics. Applies best practice techniques for model testing and tuning to assess accuracy, fit, validity, and robustness for multi-stage models and model ensembles.|Model Deployment & Scaling: Supports efforts to ensure that analytical models and techniques used can be deployed into production. Supports evaluation of the analytical model. Supports the scalability and sustainability of analytical models.|Code Development & Testing: Writes code to develop the required solution and application features by using the recommended programming language and leveraging business, technical, and data requirements. Test the code using the recommended testing approach.|Data Visualization: Generates appropriate graphical representations of data and model outcomes. Understands customer requirements to design appropriate data representation for multiple data sets. Work with User Experience designers and User Interface engineers as required to build front end applications. Presents to and influences the team and business audience using the appropriate frameworks and conveys clear messages through business and stakeholder understanding. Customize communication style based on stakeholder under guidance, and leverages rational arguments.|Guide and mentor junior associates on story types, structures, and techniques based on context.|Problem Formulation: Translates business problems within one's discipline to data related or mathematical solutions. Identifies what methods (for example, analytics, big data analytics, automation) would provide a solution for the problem. Shares use cases and gives examples to demonstrate how the method would solve the business problem.|Applied Business Acumen: Provides recommendations to business stakeholders to solve complex business issues. Develops business cases for projects with a projected return on investment or cost savings. Translates business requirements into projects, activities, and tasks and aligns to overall business strategy. Serves as an interpreter and conduit to connect business needs with tangible solutions and results. Recommends new processes and ways of working.|Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others in the application of information and best practices; supporting and aligning efforts to meet customer and business needs; and building commitment for perspectives and rationales.|Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders; identifying business needs; determining and carrying out necessary processes and practices; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and adapting to competing demands, organizational changes, and new responsibilities.|Models compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity by incorporating these into the development and implementation of business plans; using the Open Door Policy; and demonstrating and assisting others with how to apply these in executing business processes and practices.|Our Ideal Candidate Will Have|Experience with Java, Python, Pyspark, Scalding, Tensorflow, PyTorch or other related big data and machine learning technologies to design and develop robust high-performance and scalable applications|Knowledge of data analysis methods and techniques (e.g., Dimensionality reduction, predictive modeling, clustering, text mining etc.) for feature engineering.|Experience developing models with structured and unstructured data sets using advanced machine learning algorithms (Neural Networks, Regression Models, Gradient Boosting Algorithms).|Preferred Quals|Applied experience delivering to business customers using data science, machine learning, and optimization models. Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, or Econometrics. Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, pyspark, scikit learn, tensorflow, torch, scala)|About Global Tech|Imagine working in an environment where one line of code can make life easier for hundreds of millions of people and put a smile on their face. That’s what we do at Walmart Global Tech. We’re a team of 15,000+ software engineers, data scientists and service professionals within Walmart, the world’s largest retailer, delivering innovations that improve how our customers shop and empower our 2.2 million associates. To others, innovation looks like an app, service or some code, but Walmart has always been about people. People are why we innovate, and people power our innovations. Being human-led is our true disruption.|Minimum \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2909206439 (Count: 9. Index: 1200)\n",
      "|As a Lead Data Scientist, Advanced Analytics you’ll:|Work closely with internal market research and data science teams to build and deploy new solutions and capabilities on marketing measurement|Build and deploy data infrastructure and modeling platforms that enable modeling, forecasting, and optimizations of marketing plans|Manage analytical and data vendor teams|Share insights with senior executives and craft related action plans with internal stakeholders|Be a subject matter expert on marketing analytics within company who can build a high impact data science capability and be an advocate for measurement with cross functional partners|Position \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2918047131 (Count: 10. Index: 1350)\n",
      " & Responsibilities|Participate in project meetings with subject matter experts and stakeholders to understand data specific needs.|Analyze legacy data systems, entity relationships and system interfaces to detect data patterns, anomalies and trends to develop business requirements.|Develop algorithms, scripts, predictive analytics; use the right combination of tools and frameworks to turn disparate data sets into comprehensive information.|Build and implement predictive models using different multiple machine learning (ML), robotic processing automation(RPA) and natural language processing(NLP) algorithms (linear and logistic regression, time series forecasting, decision trees, survivability analysis, etc.), to develop artificial intelligence (AI) workflows.|Develop and generate data queries for data extractions and or transformations.|Analyze and develop data conversion/migration mapping logic.|Assist with query optimization and troubleshooting of database related issues. Work closely with DBA and Development teams to optimized SQL code.|Create & maintain technical documentation including analytical design and approaches diagrams, data transformations, data migration mapping and data summations.|Participate in team agile tasks and sessions such as unit testing, story estimation, sprint planning and retrospectives.|Generate data views and reports to support end users visualize results and conduct self-directed analysis; leverage presentation expertise, to present complex information to non-technical audiences.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2831485923 (Count: 11. Index: 1500)\n",
      "Experience with cloud services/platforms (e.g. AWS, Azure)|Excellent communication skills|Nice-to-have \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2914566311 (Count: 12. Index: 1650)\n",
      ":|Take advantage of massive amounts of structured data to understand how our customers interact with our product and service offerings|Proactively identify opportunities to improve the experience of businesses on the Facebook family of apps using data science|Lead the design, analysis, and interpretation of projects from data requirement gathering to data processing, modeling, and recommendations|Partner with cross-functional teams to identify new opportunities requiring the use of modern analytical and modeling techniques|Design and execute experiments (e.g., A/B testing, multi-armed bandit)|Effectively communicate insights and recommendations to business leads and influence strategic decision-making|Frequently switch between on-the-ground tactical execution and 30k foot strategy|Minimum \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2914797282 (Count: 13. Index: 1800)\n",
      ", tasks, and responsibilities. Employees may also perform other duties as assigned.|Employees must abide by all Joint Commission \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2805915187 (Count: 14. Index: 1950)\n",
      " Do|Although you will work on cutting-edge problems, this position is not a pure research position. You will participate in the engineering life-cycle at Twitter, including designing distributed systems, writing production code and data pipelines, conducting code reviews and working alongside our infrastructure and reliability teams. You’ll apply data science, machine learning, and/or graph analysis techniques to a variety of modeling and relevance problems involving users, their social graph, their tweets, and their behavior.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2845025269 (Count: 15. Index: 2100)\n",
      ":|Drive the application of rigorous data science in the development of industry solutions|Support the planning and direction of a project and effectively prioritize goals|Lead discussions at peer review and use quantitative skills to positively influence decision making|Help identify opportunities to apply the latest advancements in Machine Learning and Artificial Intelligence to build, test, and validate predictive models|Deploy your algorithms to production to identify actionable insights from large databases|Compare results from various methodologies and recommend best techniques to stakeholders|Develop and embed automated processes for predictive model validation, deployment, and implementation|Experience working closely with an engineering organization to define applications and manage them through the entire product lifecycle|Develop product artifacts such as product positioning, messaging, presentations, sales tools, marketing collateral, and product demonstrations for use in Go To Market efforts|Ensure SDLC best practices and standards are followed|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2889572461 (Count: 16. Index: 2250)\n",
      "Currently, the primary focus will be the exploration of effective algorithms and support of deduplicated material pipeline.|We’re looking for a Senior Data Scientist with a passion for both math and technology to join our growing Data Science team. This team writes the math and software that sits at the heart of our company and that runs over regularly over big data sets to produce its models.|If you join our team, you will have the opportunity to stay on the cutting edge of research and then to put this research to practical use by building your own software and infrastructure systems. When you push out your code, you will be able to see the results of your efforts ripple throughout our systems in real-time. You will design your systems as you see fit, own your code, and your work will have a very direct, measurable impact on our core metrics. Top-notch Senior Data Scientists will assume a prominent role in the development of junior staff.|We will have available to you: a weekly study group, design review forums, code reviews, as well as brainstorming sessions with peers and business stakeholders.|Highly motivated but less qualified or experienced candidates are absolutely encouraged to apply for a junior position.|Perks|Flexible remote work, unlimited PTO, health/dental/vision plans, 401k, and equity option grants are available to full-time data scientists at Verusen.|What You Will Do|Deliver a ML project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models with monitoring.|Create systems that monitor inputs and performance on a real-time basis to inform engineers when unexpected changes arise.|Use AWS ML platforms (SageMaker), and frameworks (e.g., MXNet, TensorFlow, PyTorch, SparkML, scikit-learn) to help us build ML models.|Research and implement novel ML approaches.|Work with business and engineering teams to analyze, extract, normalize, and label relevant data.|Read and conduct research to develop mathematical solutions to our most pressing problems|Engineer to put your research into practice.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2811368653 (Count: 17. Index: 2400)\n",
      "This is a fully remote role, we will consider applicants based in North America, South America and Europe.|We are looking for a Data Scientist who is innovative, highly-motivated, and proactive.|For this role, you will be part of a team that builds cutting-edge trading products in the cryptocurrency industry. You will be responsible for transforming data and generating actionable insights into our customer behavior and measuring the performance of Kraken’s products. You will collaborate and lead projects with product management, engineering, marketing, and growth teams. You will transform data from complex systems, generate performance metrics, and share the results with stakeholders at all levels of the company.|Great benefits, amazing perks, remote work, stock incentives, and a flexible PTO policy make Kraken a great place to work. If you value having a seat at the table and want to make a big impact on guiding the direction of marketing and growth at one of the top crypto exchanges in the world, this role is for you.|Responsibilities|Partner with product, engineering, marketing, finance and other relevant stakeholders to identify, prioritize, and answer the most important questions where analytics, statistical and ML modeling will have a material impact|Drive cross functional analytic projects from beginning to end: build relationships with partner teams, frame and structure questions, collect and analyze data, summarize and present key insights in support of decision making|Work with engineers to evangelize data best practices and implement analytics solutions|Develop, train, and deploy ML models serving predictions and automating business processes|Collaborate with business leaders, subject matter experts, and decision makers to develop success criteria and optimize new products, features, policies, and models|Communicate key results with self-serve tools (dashboards, analytics tools) for leadership and product management|Develop anomaly detection, and data modelling tools to monitor key performance indicators to improve the efficiency of the products|Design experiments for product teams to test hypothesis and help with idea generation and refinement|Build key datasets and data pipelines using SQL/Python/ETL frameworks|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2886945044 (Count: 18. Index: 2550)\n",
      "|As a Senior Data Scientist on our anti-cheat team, you will be a part of a global security team and will work with game and central tech development teams to:|Research and Build new statistical and machine learning models to enhance our anti-cheat capabilities|Develop core metrics aligned with EA's Positive Play Charter|Create automated dashboards and other self-service reporting tools for our partner game teams|Catalog existing available data sets, categorize their value, and suggest new features to implement to expand and enhance the quality of available data|Establish best practices for the anti-cheat team to follow as we grow the data science field within the gameplay integrity team.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2901219255 (Count: 19. Index: 2700)\n",
      "|Manage projects end-to-end from early-stage research through development, in consultation with stakeholders|Develop an understanding of Epsilon’s CORE Personalization Platform and proprietary datasets|Use your data science and machine learning expertise to research and recommend the best approaches to solving our technology and business problems|Design, implement, and validate your solutions in Apache Spark and Apache Hive, using Scala or Python on large, state-of-the-art computing clusters|Work with our Engineering teams to integrate your solutions into Epsilon’s CORE Personalization Platform|Participate fully in our collaborative approach to research and applications projects|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2808690967 (Count: 20. Index: 2850)\n",
      "Enjoy a focused and dynamic work environment with other bright, friendly people|Other \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2812310545 (Count: 21. Index: 3000)\n",
      "|Develop and maintain consultative relationships with key business stakeholders|Identify, source, transform and join public, proprietary and internal data sources|Model large structured and unstructured data sources (e.g. financial transactional, time-series, text, speech/audio and image)|Implement advanced statistical methods for prediction and optimization including a wide variety of machine learning technologies (logit, regression, decision trees/forests, boosted models, clustering, etc.) for purposes including explorative analysis, survival analysis, segmentation, prediction and recommendation systems|Perform analysis and implement solutions that maximize business impact|Prepare and present written and verbal reports to key stakeholders|Some domestic travel may be required|Execute all aspects of an advanced analytical project under guidance|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912689891 (Count: 22. Index: 3150)\n",
      ":|You own requirements gathering and ideation in a challenging problem area.|You provide expertise and leadership in solving non-trivial optimization problems in complex domain area.|You are responsible for driving end-to-end architecture, design and implementation for the analytics and data science solutions, developed by the team.|You provide leadership in software development methodologies and hands on with POC development, architect and design solutions.|Responsible for the entire analytics and data science solutions life cycle including research, design, application and deployment architecture, development, testing, continuous deployment and continuous delivery to production.|Minimum \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912562482 (Count: 23. Index: 3300)\n",
      "|Utilize code (python, etc.) and apply statistical /machine learning expertise to solve business problems. Develop scalable tools to drive automation and optimize business operations.|Develop/deploy ML-driven systems to expand capabilities and facilitate analysis within a given domain such as campaign effectiveness and incrementality, planning and forecasting, personalization, recommendation engines, pricing, fraud, and customer support.|Work with large, complex data sets. Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed. Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations.|Translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies. In cases where questions cannot be answered with available data, work with engineers and business stakeholders to produce the required data.|Maintain standards for writing clean, organized machine learning code and documentation to streamline machine learning workflow.|Provide subject matter expertise and mentorship for junior data science professionals to deliver data-driven solutions in support of established roadmaps.|Drive and promote a culture of testing & experimentation with a data-driven mindset and measurable approach.|Manage and continuously improve business user’s experience with data, including exploratory data analysis, data visualization, advanced modeling, and communication of applicable insights to audiences at varying levels of technical sophistication.|Develop partnerships with engineering and product teams to deliver on major cross-functional automation, measurement, testing, and modeling efforts.|Solve analytical problems, and effectively communicate methodologies and results both verbally and in writing.|Actively participate in ELC’s diversity and inclusion agenda. Act as a champion for inclusivity and the identification of bias in everything we do.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2874549406 (Count: 24. Index: 3450)\n",
      "This is a Contract position through Upwork’s Talent Innovation Program (TIP). Our TIP team is a global group of professionals that augment Upwork’s business. Our TIP team members are located all over the world.|Work/Project Scope|Build machine learning models that will become core components driving our marketplace|Translate business problems into machine learning solutions and clearly communicate your approach to business stakeholders.|Collaborate closely with Scientists, Engineers, Designers and Product Managers to build products end-to-end on key initiatives.|Get familiar with the user problems and pain points we’re trying to solve for Search and Recommendation.|Get proficient with our data warehouse and schemas, tools, and platforms for building DS models.|Independently drive one project or deliver one DS model from scratch to fully automated and productized.|Improve Upwork’s search and recommendation relevance using Deep Learning, NLP, Learning to Rank methods.|Must Haves (Required \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2850137279 (Count: 25. Index: 3600)\n",
      " include, but are not limited to the following:|Responsible for configuring, building and testing reports.|You will provide mentoring, guidance and supervision to Junior or Entry Level BI analysts.|You will design user-interface functionality to ensure it meets the required user experience standards.|You will be responsible for creating the user interface design and technical specifications.|You will provide valuable insights needed by the users for a more in-depth BI solution that will provide value to the Business (Campaign, Department, Initiative etc.).|You will also provide direct support to content end users.|You will ensure business KPI definitions are kept intact through the design and development process.|You will drive functional and technical end user access layer design.|You will also be responsible for detailed design, configuring, building and testing of reports according to standards.|You will fix any defects and performance problems discovered in testing.|You will be responsible for assisting and resolving design issues and defects.|You will also be responsible for the generation of regular reports and maintain associated updates and perform associated testing.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2902151424 (Count: 26. Index: 3750)\n",
      " & Responsibilities|Develop and plan analytic projects through understanding the business objectives in the team strategy roadmap|Develop robust analysis and deliverable plans to support clear and shared understanding of project requirements and goals|Develop the data, queries, tables and visualizations that deliver insight both as an individual contributor and in collaboration with team mates|Through deep subject matter expertise, create actionable recommendations to merchants on how to optimize their payment performance|Synthesize data sets to craft actionable consumer insights that support merchant growth agendas|Develop and Tableau dashboards for resilience and the functionality users need|Bring your creative solutions to the firm's biggest problems: where could our existing solutions do better?|In conjunction with data owners and department managers, contribute to the development of data models for future analytics and platforms|Collaborate with unit managers, end users, development staff, and other stakeholders to understand the business value of each analytic effort|Apply quality and service assurance best practices for analytics services and support user feedback and questions|Adhere to change control and testing processes for modifications to code and products|Skills And Experience|Bachelor's Degree in engineering, computer science, statistics, mathematics or similar technical or quantitative field|3 years or more of working in a big data analytics environment as a contributing member in self-directed roles. (A combination of advanced degree and relevant experience is acceptable.)|Experience performing distributed data analysis in a python/spark environment|Ability to clearly develop and document analytic requirements with stakeholders|AWS developer, or data analytics specialty experience is highly desirable|Experience in the payments industry and/or technology-enabled industries is desirable|General \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2896621365 (Count: 27. Index: 3900)\n",
      "If you love driving critical thinking and insight into challenging, unstructured problems and working with leaders in the organization to bring those insights into action, this role is for you. This is a hands-on role, however, being a part of a small team gives opportunity to take ownership of the customer / business problem across the spectrum.|Data Science Analytics Topics Include, But Not Limited To|Product / Value Proposition design|Customer Experience improvement|Business Planning & Forecasting|Predictive Analytics (a number of customer-centric use-cases)|NLP / Text mining to identify themes in customer feedback|About Us|Inclusive Team Culture|Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.|Work/Life Balance|Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.|Mentorship & Career Growth|Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded engineer and enable them to take on more complex tasks in the future.|Basic \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2913669648 (Count: 28. Index: 4050)\n",
      "|Our behavioral analytics team supports a wide variety of federal agency client needs focused on detecting fraudulent electronic transactions/usage. Team members will work collaboratively with the Noblis data analytics architects and data scientists to design and implement an offline and near real time analytics capability, visualization and a near real-time dash boarding and visualization capabilities to support Federal Agencies in strengthening their security posture against fraudulent web transactions to support Federal Agencies in strengthening their security posture against fraudulent transactions.|As part of the design and implementation effort, the data analytics developer will participate in various aspects of the implementation, including synthesizing large scale system/communications logs, development of analytical data sets, and development of fraud models to identify anamolous transactions.|The Data Scientist will work closely with team members on the Data Science team and federal Government personnel.|Responsibilities Include|Identification of analytics approaches, and development of supporting analytical data sets.|Development of fraud risk models based on feastures extracted from user application interactions, log transactions, network data, third party data, and other key data sources.|Application of AI and ML techniques in developing and training fraud detection models, including application of graph analytics|Development of integrated data sets, including the design and implementation of data integration across data analytics infrastructures as needed to support data analytics projects.|Documentation of hypothesis, analytics approaches, and findings.|Development of dashboards and reports to assess data performance and quality control.|Assist with the development of project status briefings and dashboards for Agency executives|Interact with senior client project team members and operational staff|Client Engagement|Support and lead evolving business development efforts by applying technical and functional expertise to develop business solutions.|Lead proposal sections for small or limited competition proposals and actively participate in teaming strategy discussions|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2898424262 (Count: 29. Index: 4200)\n",
      "|Guidehouse is a leading global provider of consulting services to the public and commercial markets with broad capabilities in management, technology, and risk consulting. We help clients address their toughest challenges and navigate significant regulatory pressures with a focus on transformational change, business resiliency, and technology-driven innovation. Across a range of advisory, consulting, outsourcing, and digital services, we create scalable, innovative solutions that prepare our clients for future growth and success. The company has more than 10,000 professionals in over 50 locations globally. Guidehouse is a Veritas Capital portfolio company, led by seasoned professionals with proven and diverse expertise in traditional and emerging technologies, markets, and agenda-setting issues driving national and global economies. For more information, please visit: www.guidehouse.com.|Responsibilities|Apply statistical and programming skills to convert raw data into insights that help clients understand and mitigate fraud threats.|Analyze the effectiveness of existing fraud models and oversee the design, development, and management of new real-time fraud rules and models.|Research and apply the latest machine learning algorithms to power analytical solutions for managing fraud problems in the market.|Collaborate with clients and domain experts to drive the development and optimization of machine learning fraud models.|Responsible for day-to-day activities of a project including interaction with other team members, professionals from other firms involved in the engagement, and client personnel.|Own data science areas such from analytics roadmap and prioritization to definition of KPIs and developing new ways of understanding customer feature engagement.|Prepare reports, written analyses, quantitative exhibits, and other client deliverables regarding projects and/or results of work performed.|Required|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2844508455 (Count: 30. Index: 4350)\n",
      " Be Doing (ie. Job Duties)|Build Machine Learning powered engines and pipelines to power notifications, content feeds, and other recommendation systems.|Build and launch excellent productionalized, low-maintenance models.|Explore and leverage state of the art machine learning techniques for a variety of problems at the intersection of Machine Learning and Crypto.|Setup A/B experiments and iterate until impact is landed.|What We Look For In You (ie. Job \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2844510559 (Count: 31. Index: 4500)\n",
      " Be Doing (ie. Job Duties)|Build Machine Learning powered engines and pipelines to power notifications, content feeds, and other recommendation systems.|Build and launch excellent productionalized, low-maintenance models.|Explore and leverage state of the art machine learning techniques for a variety of problems at the intersection of Machine Learning and Crypto.|Setup A/B experiments and iterate until impact is landed.|What We Look For In You (ie. Job \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2892145060 (Count: 32. Index: 4650)\n",
      "In a typical branch office, a financial advisor meets with clients and receives branch office support, so they can focus on building deep relationships with clients. Headquarters associates in St. Louis, Tempe and Mississauga provide support and expertise to help U.S. and Canada branch teams deliver an ideal client experience. We continue to grow to meet the needs of long-term individual investors.|Job-Overview|Firm Analytics|Senior Data Scientist|The Senior Data Scientist is responsible for the design and development of complex mathematical methods, machine learning and statistical models in support of data driven strategies. The role requires the ability to leverage data from multiple sources to develop innovative solutions to business problems.|An ideal candidate must be able to work closely with business partners to identify and develop tailored analytic solutions. A senior data scientist will be responsible for leading projects from design through implementation and final delivery to internal business partners.|Key Responsibilities|Use statistical modeling, machine learning and numerical optimization to discover and leverage patterns in data using...Time Series Analysis, Classification Algorithms, Clustering, Regressions, Recommender Systems, Linear/Nonlinear Optimization, Monte-Carlo simulation, text mining, natural language processing|Define data needs and evaluate data quality for applicability to posed problems|Ability to create features and develop models beyond standard toolset libraries to meet unique business challenges.|Interpret and communicate findings and insights from the data to business partners|Mentor junior Data Scientist|Skills-\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2813404873 (Count: 33. Index: 4800)\n",
      "|Work with data science techniques and libraries to show data's applicability to business problems.|Perform exploratory data analysis to define analytical models.|Develop advanced quantitative models using a variety of programs/software to support predictive assessments.|Provide expertise for analytical, programmatic, strategic, and operational analysis.|Explain analytics model behavior/results in the vernacular of business.|Perform technical risk analysis and reliability assessments.|Perform multiple forms of advanced analyses, sustainment, optimization, text analytics, machine learning, parametric and non-parametric statistical models and techniques.|Build, test, validate and demonstrate analytical models through various relevant error metrics and calibration techniques.|Provide recommendations for plans, programs, strategies, policies and budgets.|Design algorithms that require a number of different models/methods to be used in an ensemble.|Deploy models into production.|The Team|Analytics & Cognitive|In this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.|The Analytics & Cognitive team leverages the power of data, analytics, robotics, science and cognitive technologies to uncover hidden relationships from vast troves of data, generate insights, and inform decision-making. Together with the Strategy practice, our Strategy & Analytics portfolio helps clients transform their business by architecting organizational intelligence programs and differentiated strategies to win in their chosen markets.|Analytics & Cognitive will work with our clients to:|Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms.|Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions.|Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2798510917 (Count: 34. Index: 4950)\n",
      " Include|The Business Prime team is looking for an experienced and motivated Senior Data Scientist to generate data-driven insights influencing the Business Prime direction, build the necessary predictive models, optimization algorithms and customer behavioral segments allowing us to discover and expand the value proposition of Business Prime to the customers.|Customer lifecycle analysis improving targeting, customer identification, and spend behavior.|Data driven insights to accelerate acquisition of new members.|Grow benefits adoption based on customer segment, vertical, and drive customers to their \"aha moment\".|Predict customers at risk of churn and declining engagement.|Identify ineligible accounts including fraud, abuse, and other undesired behaviors.|Experiments to enhance membership value for B2B customers.|In this role, you will be a technical expert with significant scope and impact. You will work with Business Intelligence Engineers, Financial Analysts, Product Managers, Software Engineers, Data Engineers, and other Data Scientists, to build new and enhance existing ML models to optimize customer experience. The successful Data Scientist will have extreme bias for action needed in a startup environment, with outstanding leadership skills, proven ability to build and manage medium-scale modeling projects, identify data requirements, build methodology and tools that are statistically grounded. We are seeking someone who can thrive in a fast-paced, high-energy and fun work environment where we deliver value incrementally and frequently. We value highly technical people who know their subject matter deeply and are willing to learn new areas. We look for individuals who know how to deliver results and show a desire to develop themselves, their colleagues, and their career.|Basic \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2912072132 (Count: 35. Index: 5100)\n",
      "|The Data Scientist reports to the CEO. Responsibilities include:|Analyse data, produce relevant visualisations, identify clusters and outliers.|Find correlations and causal relationships in the data|Propose ways to model these relationships in mathematical formulae|Present progress and any challenges encountered.|Write clean, reusable code and clear documentation|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2889548715 (Count: 36. Index: 5250)\n",
      "|Strong stakeholder engagement – being the bridge between tehcnicalk and non-technical|Design machine learning based prototype applications.|Analyze large data in order to generate tangible insights.|Advise on data collection for machine learning models deployment.|Identify novel techniques for business process improvement and automation.|Educate others on statistical analysis and scientific investigation.|Collaborate with AI & Automation and clients.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2911309499 (Count: 37. Index: 5400)\n",
      ":|·        Design, build, and refine scalable data pipelines for the active products going to market.|·        Build a robust model management solution that incorporates A/B Testing and CI/CD.|·        Develop a model and data versioning policy and ensure the engineers adhere to it.|·        Automate infrastructure maintenance and management for our cloud hosted ML workflows.|·        Work directly with ML engineers and customers to enable successful deployments of solutions to our embedded end product.|·        Integrate new data pipelines as additional vehicle lines and projects are supported in the future.|Experience, Background and \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2887596808 (Count: 38. Index: 5550)\n",
      " do...|Within Walmart we have an organization that is transforming the future of Walmart’s omnichannel supply chain strategy, we call ourselves CENTROID. Our team of industry-leading experts, consultants, and technologists combine exceptional strategic thinking with data science and advanced analytics to solve the world’s most complex supply chain challenges at Walmart’s scale.|Our mission is to design a supply chain that leverages Walmart’s unique advantages to provide a wide product assortment, offer the lowest costs, and build cutting-edge capabilities through transformative initiatives. We’re looking for extraordinary supply chain talent with top-notch quantitative abilities, critical thinking skills, and business acumen to propel Walmart through the next 50 years of excellence and innovation.|Job Description|We’re looking for a Principal Data Scientist to lead and create initiatives for future strategies across Walmart’s omnichannel supply chain. This is a high-impact, high-visibility role within the organization with expectations to deliver immediate results. In this role, you’ll primarily be responsible for creating a long-term strategy and transformative path for Walmart’s rapidly growing omnichannel business.|Responsibilities|Conceptualize, design, and execute strategic initiatives from start to finish, including cross-functional project management, data collection and manipulation, analysis and modeling, and the communication of insights and recommendations|Guide team members and build scalable and complex supply chain models and processes to optimize supply chain strategies with the goal of delivering an excellent customer experience while balancing operating cost and asset efficiency|Simultaneously and independently manage multiple strategic initiatives while ensuring deadlines are met and the desired business impact is achieved|Develop strong relationships and influence cross-functional areas to implement best practices and execute interdisciplinary initiatives|Partner closely with cross-functional teams to identify areas of opportunity and drive results|Ensure continuous alignment from relevant business partners and leaders to gain support for new initiatives and lead change management of existing practices|Communicate clearly and persuasively via email, verbally, and in presentations to influence decisions across senior leaders from various functional areas|You Will Thrive In This Role If You|Bring a high degree of originality and creativity when developing solutions to improve existing business processes within the supply chain, utilizing methods such as statistical analysis, regression modeling, and optimization|Are adept at dealing with ambiguity and making independent decisions about what data and approach is best for the task at hand|Excel in communicating with individuals and groups at all levels of an organization|Potential Projects Include|Create models to analyze the Supply Chain network needed to support future sales growth with scenario modeling capabilities to understand the sensitivity to multiple variables; opening, closing, or repurposing distribution centers; conduct scenario analysis to evaluate multiple networks designs and impact to customer experience and cost to serve|Develop optimization logic and a tool to determine truckload lane strategy for outbound transportation, balancing cost and SLA requirements|Preferred \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2902024722 (Count: 39. Index: 5700)\n",
      "Job Description|As a data scientist in Wood Mackenzie, a Verisk company, you will leverage data scientist and data processing tools to work with our top financial analytics in energy industry both from internal and external clients to provide data insights to them to make important investment recommendations or decisions.|You would have the opportunity to work on the most interesting and challenging data in energy industry. You will be challenged to continue adopting and developing cutting-edge digital technologies on data science, as well as data processing platforms.|You will work with the best in the field of data scientist and growing your skills from working on our team and making significant impact on our business initiatives.|About The Role|This role will be part of the data asset team work working as part of a cross functional team to deliver best in class data and analytics to our clients. The mission of this team is to develop the best quality of data through leveraging ML models and AI technologies. It will further help to scale up the operation through applying the innovative technology expanding into getting new data insights for our clients in current and future adjacency domains. You will be working with a very talented team as well as our partners including AWS.|You will be thrilled everyday as being at the very frontline of data science and big data processing technologies. Come to join us if you would like to applying your data scientist skills to solve the challenges and would like to become world class data scientists while learning how to get the best data to help to make energy investment decisions.|The role will can be in places where Verisk had business offices in US or Canada.|The level of appointment to which band on the company banding structure will be dependent on your skills, experience and capabilities demonstrated at assessment prior to offer of employment.|\n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2916072770 (Count: 40. Index: 5850)\n",
      "Optum Payer Decision Intelligence is looking to expand and is seeking a Sr. Data Scientist/ ML Engineer to join our team and help us reach our goals of accurate and effortless payments of claims through advanced analytics and machine learning. You should be an exceptional disciplined and self-motivated Data Scientist with Machine Learning, Anomaly Detection, and Data Engineering experience and a passion for working with healthcare data.|You'll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges.|Primary Responsibilities|Help us build out our MLOps system for tracking, maintaining, interpreting, and retraining our production models|Work alongside other data scientists and engineers to design and implement our model performance tracking system which includes detecting data drift and other anomalies through both simple and advanced anomaly detection methods, maintaining data pipelines, writing quality code, preparing interactive visualizations, and writing documentation|Conduct hands-on data analysis on large datasets|Effectively communicate complex technical results to business partners|Work with a great deal of autonomy to find solutions to complex problems|You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.|Required \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2810589970 (Count: 41. Index: 6000)\n",
      "|Work with software leads in experimenting with and applying Machine Learning into our products in ethically responsible ways;|Mine and analyze data from different data sources to drive optimization and improvement of our products;|Use predictive modelling to increase and optimize analytics outcomes of our products;|Assess the effectiveness and accuracy of new data sources and data gathering techniques;|Develop custom data models and algorithms to apply to data sets;|Develop company A/B testing framework and test model quality;|Coordinate with different functional teams to implement models and monitor outcomes;|Develop processes and tools to monitor model performance over time and analyze data accuracy;|Experience And Key \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2807419994 (Count: 42. Index: 6150)\n",
      " Do|Help drive the Crunchbase personalization engine and turn our business vision into features|Collaborate with the product team and other partners to help improve our personalized user experience|Work on all aspects of the feature delivery cycle, from conceptualizing and collecting requirements to modeling and productionalizing your code all the way to deployment.|Set up evaluation processes and methodologies with partners to guide experiments|Conduct research to implement prescriptive and predictive models at a production level of quality according to our business needs, data patterns, and performance requirements|Work side by side with machine learning engineers and data engineers to come up with plans to put the models/algorithms into production|Develop statistical and machine learning models to better understand users and their journey in general|Contribute to defining and enhancing our machine learning platform capabilities from the ground up|Help establish processes and standard methodologies to help grow our data science guild|What We're \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2911999313 (Count: 43. Index: 6300)\n",
      "|Artificial Intelligence (AI) and Machine Learning (ML) are one of the most strategic & fastest growing businesses opportunities. Autodesk has made a major move into this area with use cases in various stages in finance. We are designing and building innovative solutions using these emerging technologies to digitize the future of finance. As a data scientist you’ll develop artificial intelligence and machine learning solutions with cutting edge technologies, learn about different enterprise functions in finance and how emerging technologies such as AI and ML are disrupting these industries.|Responsibilities|Partner and develop strong relationships with cross-functional teams|Process, manipulate and understand ‘Data’ from variety of sources|Utilize machine learning models to deliver meaningful business insights|Build a practical product that can automate/improve an existing process|Make a cross-functional impact with our finance & operations organization|Minimum \n",
      "\n",
      "\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/2853455861 (Count: 44. Index: 6450)\n",
      "|Once in the team you will bring your machine learning expertise to bear on all aspects of the trade pipeline. You must have the ability to build models for high-frequency asset price prediction, to analyse the resulting trades, and to build models for better understanding of latency implications, etc. You must be able to explain clearly your ideas and results to the rest of the team.|In the role you will:|Contribute techniques from machine learning towards improved automated trading systems.|Work with traders, quants, software developers in a highly focused team building, deploying and improving automated trading systems.|Research, implement, test, deploy and monitor proprietary systems trading across multiple markets and financial products. We work at all levels of the problem domain from market data handlers through trade monitoring.|Work with python systems to extract the data you will require; (Preferable C++ but not a must)|What we're \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter, print_counter = 0, 0\n",
    "\n",
    "for key, value in job_responsibilities.items():\n",
    "    if counter%150 == 0 :\n",
    "        print_counter +=1\n",
    "        print(f\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{key} (Count: {print_counter}. Index: {counter})\")\n",
    "        print(value['responsibilities'])\n",
    "        print(\"\\n\")\n",
    "\n",
    "    counter += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "data": {
      "text/plain": "6344"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_responsibilities)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "18"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# short_count = 0\n",
    "#\n",
    "# for key, value in job_responsibilities.items():\n",
    "#     if len(value) < 75:\n",
    "#         short_count +=1\n",
    "#\n",
    "# short_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             responsibilities           title  \\\n2908496770  :|•\\tDesign and implement ML methods on propri...  Data Scientist   \n2911267267  :|• Provide consultative support as and when r...  Data Scientist   \n2912844894  :|Support Data and Analytics team through deve...  Data Scientist   \n2911205495  |Build agent-based simulations of smart contra...  Data Scientist   \n2912480226  |Productionize, launch, and monitor predictive...  Data Scientist   \n\n                                                  description  \\\n2908496770  <html><body><div class=\"description__text desc...   \n2911267267  <html><body><div class=\"description__text desc...   \n2912844894  <html><body><div class=\"description__text desc...   \n2911205495  <html><body><div class=\"description__text desc...   \n2912480226  <html><body><div class=\"description__text desc...   \n\n                companyName                location   level  \n2908496770  Data Revolution  San Francisco Bay Area  senior  \n2911267267       TrueSkilla           United States  senior  \n2912844894   Project Canary              Denver, CO     mid  \n2911205495         Gauntlet           United States     mid  \n2912480226            Miles        Redwood City, CA     mid  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>responsibilities</th>\n      <th>title</th>\n      <th>description</th>\n      <th>companyName</th>\n      <th>location</th>\n      <th>level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2908496770</th>\n      <td>:|•\\tDesign and implement ML methods on propri...</td>\n      <td>Data Scientist</td>\n      <td>&lt;html&gt;&lt;body&gt;&lt;div class=\"description__text desc...</td>\n      <td>Data Revolution</td>\n      <td>San Francisco Bay Area</td>\n      <td>senior</td>\n    </tr>\n    <tr>\n      <th>2911267267</th>\n      <td>:|• Provide consultative support as and when r...</td>\n      <td>Data Scientist</td>\n      <td>&lt;html&gt;&lt;body&gt;&lt;div class=\"description__text desc...</td>\n      <td>TrueSkilla</td>\n      <td>United States</td>\n      <td>senior</td>\n    </tr>\n    <tr>\n      <th>2912844894</th>\n      <td>:|Support Data and Analytics team through deve...</td>\n      <td>Data Scientist</td>\n      <td>&lt;html&gt;&lt;body&gt;&lt;div class=\"description__text desc...</td>\n      <td>Project Canary</td>\n      <td>Denver, CO</td>\n      <td>mid</td>\n    </tr>\n    <tr>\n      <th>2911205495</th>\n      <td>|Build agent-based simulations of smart contra...</td>\n      <td>Data Scientist</td>\n      <td>&lt;html&gt;&lt;body&gt;&lt;div class=\"description__text desc...</td>\n      <td>Gauntlet</td>\n      <td>United States</td>\n      <td>mid</td>\n    </tr>\n    <tr>\n      <th>2912480226</th>\n      <td>|Productionize, launch, and monitor predictive...</td>\n      <td>Data Scientist</td>\n      <td>&lt;html&gt;&lt;body&gt;&lt;div class=\"description__text desc...</td>\n      <td>Miles</td>\n      <td>Redwood City, CA</td>\n      <td>mid</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(job_responsibilities, orient='index')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "(6512, 6)"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "df2 = df.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "(6361, 6)"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "df2.to_pickle('big_job_df.pickle')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         responsibilities           title  \\\ncount                                                6361            6361   \nunique                                               4001            2152   \ntop     |PwC Professional skills and responsibilities ...  Data Scientist   \nfreq                                                   70            1172   \n\n                                              description companyName  \\\ncount                                                6361        6361   \nunique                                               4546        1916   \ntop     <html><body><div class=\"description__text desc...    Deloitte   \nfreq                                                   59         328   \n\n            location level  \ncount           6361  6361  \nunique           761     3  \ntop     New York, NY   mid  \nfreq             330  3651  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>responsibilities</th>\n      <th>title</th>\n      <th>description</th>\n      <th>companyName</th>\n      <th>location</th>\n      <th>level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6361</td>\n      <td>6361</td>\n      <td>6361</td>\n      <td>6361</td>\n      <td>6361</td>\n      <td>6361</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>4001</td>\n      <td>2152</td>\n      <td>4546</td>\n      <td>1916</td>\n      <td>761</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>|PwC Professional skills and responsibilities ...</td>\n      <td>Data Scientist</td>\n      <td>&lt;html&gt;&lt;body&gt;&lt;div class=\"description__text desc...</td>\n      <td>Deloitte</td>\n      <td>New York, NY</td>\n      <td>mid</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>70</td>\n      <td>1172</td>\n      <td>59</td>\n      <td>328</td>\n      <td>330</td>\n      <td>3651</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "data": {
      "text/plain": "'2908496770'"
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[0].name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.series.Series"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df2.responsibilities)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def cell_count_containing(series, term):\n",
    "    count = series.str.contains(term, case=False).sum()\n",
    "    percent = count / len(series) * 100\n",
    "    return f\"{term}: {count}  ({percent:.1f}%)\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "terms = ['data', 'machine', 'machine learning', 'walmart', 'amazon', 'microsoft', 'jpmorgan', 'vaccine']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "['data: 3781  (88.0%)',\n 'machine: 2162  (50.3%)',\n 'machine learning: 2090  (48.7%)',\n 'walmart: 102  (2.4%)',\n 'amazon: 161  (3.7%)',\n 'microsoft: 76  (1.8%)',\n 'jpmorgan: 15  (0.3%)',\n 'vaccine: 26  (0.6%)']"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cell_count_containing(df2.responsibilities, t) for t in terms]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}